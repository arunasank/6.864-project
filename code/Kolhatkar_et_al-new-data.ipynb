{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "435e5a37",
   "metadata": {},
   "source": [
    "# Kolhatkar et al parallels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "594ca83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install simpledorff\n",
    "!pip3 install krippendorff\n",
    "!pip3 install nltk\n",
    "!pip3 install py-readability-metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fff2372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install spacy\n",
    "!pip3 install spacy_readability\n",
    "!python3 -m spacy download en_core_web_sm\n",
    "!pip3 install spacy-transformers\n",
    "!pip3 install pyspellchecker\n",
    "!pip3 install sklearn-pandas\n",
    "!pip3 install tqdm>=4.61.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ec870a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.10\n",
      "\u001b[33mWARNING: The directory '/u/arunas/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /u/arunas/.local/lib/python3.8/site-packages (4.62.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 --version\n",
    "!pip3 install tqdm --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7f60064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-_75e2q84 because the default path (/u/arunas/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n",
      "<ipython-input-4-cc521505c3c5>:31: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tqdm_notebook().pandas()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43b7eaa32cf46d0a10c497bf7a2fc64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /u/arunas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import simpledorff\n",
    "import krippendorff\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import spacy\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from spellchecker import SpellChecker\n",
    "import sklearn_pandas\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "\n",
    "spellchk = SpellChecker()\n",
    "\n",
    "# tqdm.pandas()\n",
    "tqdm_notebook().pandas()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ae111ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/baselines/train-mod.csv')\n",
    "test = pd.read_csv('../data/baselines/test-mod.csv')\n",
    "val = pd.read_csv('../data/baselines/val-mod.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49049d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_dataframe(dataset):\n",
    "    dataset_ratings = dataset.filter(regex=('author_id|participantId|noteId|output|scaling|tweet_text|summary'))\n",
    "    dataset_ratings = dataset_ratings.groupby(['noteId', 'participantId', 'summary', 'tweet_text', 'tweet_author_id']).size().to_frame(name = 'count').reset_index().merge(dataset_ratings)\n",
    "    dataset_ratings['full_text'] = dataset_ratings.apply(lambda row: f'<BEG> {row[\"tweet_text\"]} <SEP> {row[\"summary\"]} <END>', axis=1)\n",
    "    dataset_unique = pd.DataFrame(dataset_ratings['full_text'].unique())\n",
    "    dataset_unique['full_text'] = dataset_unique[0]\n",
    "    dataset_unique = dataset_unique.drop(0, 1)\n",
    "    dataset_unique['ner_count'] = dataset_unique['full_text'].apply(lambda row: len(nlp(row).ents))\n",
    "    dataset_ratings = pd.merge(dataset_ratings, dataset_unique, on='full_text')\n",
    "    dataset_ratings['full_text_tokens'] = dataset_ratings.apply(lambda row: nltk.word_tokenize(row['full_text']), axis=1)\n",
    "    dataset_ratings['full_text_average_word_length'] = dataset_ratings.apply(lambda row: np.mean([len(token) for token in row['full_text_tokens']]), axis=1)\n",
    "    dataset_ratings[\"full_text_sentences\"] = dataset_ratings.apply(lambda row: nltk.sent_tokenize(row['full_text']), axis=1)\n",
    "    dataset_ratings['full_text_sentences_mean_word_count'] = dataset_ratings.apply(lambda row: np.mean([len(sentence.split(' ')) for sentence in row['full_text_sentences']]), axis=1)\n",
    "    return dataset_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95b5bbd",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a8f5127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import string\n",
    "\n",
    "porter = nltk.PorterStemmer()\n",
    "with open(\"../data/personal.txt\") as f:\n",
    "    personal_words = f.read().splitlines()\n",
    "\n",
    "class TextStatistics(object):\n",
    "    '''\n",
    "    classdocs\n",
    "    '''\n",
    "\n",
    "\n",
    "    def __init__(self, text):\n",
    "        '''\n",
    "        Constructor\n",
    "        '''\n",
    "        self.text = self.clean_text(text)\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        if text is None:\n",
    "            return self.text\n",
    "\n",
    "        full_stop_tags = ['li', 'p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'dd']\n",
    "\n",
    "        for tag_name in full_stop_tags:\n",
    "            text = text.replace(\"</%s>\" % tag_name, \".\")\n",
    "\n",
    "        \"\"\"\n",
    "        Regular expressions that are to be replaced\n",
    "        \"\"\"\n",
    "        replacement_expressions = [ [\"<[^>]+>\", \"\"], #Strip tags\n",
    "                                   [\"[,:;()\\\\-]\", \" \"],  #Replace commas, hyphens etc (count them as spaces)\n",
    "                                   [\"[\\\\.!?]\", \".\"], #unify terminators\n",
    "                                   [\"^\\\\s+\", \"\"], #strip leading whitespace\n",
    "                                   [\"[ ]*(\\\\n|\\\\r\\\\n|\\\\r)[ ]*\", \" \"], #Replace new lines with spaces\n",
    "                                   [\"([\\\\.])[\\\\. ]+\", \".\"],#check for duplicated terminators\n",
    "                                   [\"[ ]*([\\\\.])\", \". \"], #Pad sentence terminators\n",
    "                                   [\"\\\\s+\", \" \"], #Remove multiple spaces\n",
    "                                   [\"\\\\s+$\", \"\"]] #strip trailing white space\n",
    "\n",
    "        for replacement_set in replacement_expressions:\n",
    "            text = re.compile(replacement_set[0]).sub(\n",
    "                                          replacement_set[1], text)\n",
    "\n",
    "        #Add final terminator in case it's missing.\n",
    "        if len(text) > 0 and text[-1] != '.':\n",
    "            text += '.'\n",
    "\n",
    "        return text\n",
    "\n",
    "    def flesch_kincaid_reading_ease(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "        return round((206.835 - (1.015 * self.average_words_per_sentence(text)) - (84.6 * self.average_syllables_per_word(text)))*10)/10\n",
    "\n",
    "    def flesch_kincaid_grade_level(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "        return round(((0.39 * self.average_words_per_sentence(text)) + (11.8 * self.average_syllables_per_word(text)) - 15.59)*10)/10\n",
    "\n",
    "    def gunning_fog_score(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "        return round(((self.average_words_per_sentence(text) + self.percentage_words_with_three_syllables(text, False)) * 0.4)*10)/10\n",
    "\n",
    "    def coleman_liau_index(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "        return round(((5.89 * (self.letter_count(text) / self.word_count(text))) - (0.3 * (self.sentence_count(text) / self.word_count(text))) - 15.8 ) *10)/10\n",
    "\n",
    "    def smog_index(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "        return round(1.043 * math.sqrt((self.words_with_three_syllables(text) * (30 / self.sentence_count(text))) + 3.1291)*10)/10\n",
    "\n",
    "    def automated_readability_index(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "        return round(((4.71 * (self.letter_count(text) / self.word_count(text))) + (0.5 * (self.word_count(text) / self.sentence_count(text))) - 21.43)*10)/10;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def syllable_count(self, word):\n",
    "        syllable_count = 0\n",
    "        prefix_suffix_count = 0\n",
    "        word_part_count = 0\n",
    "\n",
    "        word = word.lower()\n",
    "        word = re.compile(\"[^a-z]\").sub(\"\", word)\n",
    "\n",
    "        problem_words = {\n",
    "            \"simile\":        3,\n",
    "            \"forever\":        3,\n",
    "            \"shoreline\":    2\n",
    "        }\n",
    "\n",
    "        if word in problem_words:\n",
    "            return problem_words[word]\n",
    "\n",
    "        #These syllables would be counted as two but should be one\n",
    "        sub_syllables = [\n",
    "            \"cial\",\n",
    "            \"tia\",\n",
    "            \"cius\",\n",
    "            \"cious\",\n",
    "            \"giu\",\n",
    "            \"ion\",\n",
    "            \"iou\",\n",
    "            \"sia$\",\n",
    "            \"[^aeiuoyt]{2,}ed$\",\n",
    "            \".ely$/\",\n",
    "            \"[cg]h?e[rsd]?$\",\n",
    "            \"rved?$\",\n",
    "            \"[aeiouy][dt]es?$\",\n",
    "            \"[aeiouy][^aeiouydt]e[rsd]?$\",\n",
    "            \"^[dr]e[aeiou][^aeiou]+$\", # Sorts out deal, deign etc\n",
    "            \"[aeiouy]rse$\" # Purse, hearse\n",
    "        ]\n",
    "\n",
    "        #These syllables would be counted as one but should be two\n",
    "        add_syllables = [\n",
    "            \"ia\",\n",
    "            \"riet\",\n",
    "            \"dien\",\n",
    "            \"iu\",\n",
    "            \"io\",\n",
    "            \"ii\",\n",
    "            \"[aeiouym]bl$\",\n",
    "            \"[aeiou]{3}\",\n",
    "            \"^mc\",\n",
    "            \"ism$\",\n",
    "            \"([^aeiouy])\\\\1l$\",\n",
    "            \"[^l]lien\",\n",
    "            \"^coa[dglx].\",\n",
    "            \"[^gq]ua[^auieo]/\",\n",
    "            \"dnt$\",\n",
    "            \"uity$\",\n",
    "            \"ie(r|st)$\"\n",
    "        ]\n",
    "\n",
    "        # Single syllable prefixes and suffixes\n",
    "        prefix_suffix = [\n",
    "            \"^un\",\n",
    "            \"^fore\",\n",
    "            \"ly$\",\n",
    "            \"less$\",\n",
    "            \"ful$\",\n",
    "            \"ers?$\",\n",
    "            \"ings?$\"\n",
    "        ]\n",
    "\n",
    "        #Remove prefixes and suffixes and count how many were taken\n",
    "        for current_prefix_suffix in prefix_suffix:\n",
    "            pattern = re.compile(current_prefix_suffix)\n",
    "            if pattern.match(word) is not None:\n",
    "                word = pattern.sub(\"\", word)\n",
    "                prefix_suffix_count = prefix_suffix_count + 1\n",
    "\n",
    "        word_parts = list(filter(textstats_is_not_whitespace,\n",
    "                             re.split(\"[^aeiouy]+\", word)))\n",
    "\n",
    "        word_part_count = len(word_parts)\n",
    "        x = 5\n",
    "\n",
    "        syllable_count = word_part_count + prefix_suffix_count\n",
    "        for current_sub in sub_syllables:\n",
    "            if re.match(current_sub, word) is not None:\n",
    "                syllable_count = syllable_count - 1\n",
    "\n",
    "        for current_sub in add_syllables:\n",
    "            if re.match(current_sub, word) is not None:\n",
    "                syllable_count = syllable_count + 1\n",
    "\n",
    "        return max(syllable_count, 1)\n",
    "\n",
    "    def text_length(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "        return len(text)\n",
    "\n",
    "    def letter_count(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "        #strangely - re.IGNORECASE will leave the last . on text\n",
    "        repl = re.sub(\"[^a-z|A-Z]+\", \"\", text)\n",
    "        return len(repl)\n",
    "\n",
    "\n",
    "    def sentence_count(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "        text = re.sub(\"[^\\\\.!?]\", \"\", text)\n",
    "        return max(len(text), 1)\n",
    "\n",
    "    def words_with_three_syllables(self, text = None, count_proper_nouns = True):\n",
    "        text = self.clean_text(text)\n",
    "        long_word_count = 0\n",
    "\n",
    "        word_parts = re.split(\"s+\", text)\n",
    "        for word in word_parts:\n",
    "            # We don't count proper nouns or capitalised words if the countProperNouns attribute is set.\n",
    "            #Defaults to true.\n",
    "            if re.match(\"^[A-Z]\", text) is None or count_proper_nouns:\n",
    "                if self.syllable_count(word) > 2:\n",
    "                    long_word_count += 1\n",
    "\n",
    "        return long_word_count\n",
    "\n",
    "    def percentage_words_with_three_syllables(self, text = None, count_proper_nouns = True):\n",
    "        text = self.clean_text(text)\n",
    "        return self.words_with_three_syllables(text, count_proper_nouns) / self.word_count(text)\n",
    "\n",
    "    def word_count(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "\n",
    "        #In case of a zero length item... split will return an array of length 1\n",
    "        if len(text) == 0:\n",
    "            return 0\n",
    "\n",
    "        return len(self.get_words(text))\n",
    "\n",
    "    def get_words(self, cleaned_text):\n",
    "        return re.split(\"[^a-zA-Z0-9]+\",cleaned_text)\n",
    "\n",
    "    def get_distinct_words(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "        word_arr = re.split(\"[^a-zA-Z0-9]+\", text)\n",
    "        distinct_word_arr = []\n",
    "        for word in word_arr:\n",
    "            word = word.lower()\n",
    "            word = re.sub(\"[^a-zA-Z]\",\"\", word)\n",
    "            if word not in distinct_word_arr:\n",
    "                distinct_word_arr.append(word)\n",
    "\n",
    "        return distinct_word_arr\n",
    "\n",
    "    def word_count_distinct(self, text = None):\n",
    "        \"\"\"Count the number of distinct different words\"\"\"\n",
    "        word_arr = self.get_distinct_words(text)\n",
    "        return len(word_arr)\n",
    "\n",
    "\n",
    "\n",
    "    def average_syllables_per_word(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "\n",
    "        syllable_count = 0\n",
    "        word_count = self.word_count(text)\n",
    "        word_arr = self.get_words(text)\n",
    "        for word in word_arr:\n",
    "            syllable_count += self.syllable_count(word)\n",
    "\n",
    "        return float(max(syllable_count, 1)) / float(max(word_count, 1))\n",
    "\n",
    "    def max_syllables_per_word(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "\n",
    "        max_value = 0\n",
    "        word_arr = self.get_words(text)\n",
    "        for word in word_arr:\n",
    "            num_syllables = self.syllable_count(word)\n",
    "            if num_syllables > max_value:\n",
    "                max_value = num_syllables\n",
    "\n",
    "        return max_value\n",
    "\n",
    "\n",
    "    def average_words_per_sentence(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "        return float(self.word_count(text)) / float(self.sentence_count(text))\n",
    "\n",
    "    def max_words_per_sentence(self, text = None):\n",
    "        #split into sentences\n",
    "        text = self.clean_text(text)\n",
    "        sentence_arr = re.split(\"[\\\\.!?]\", text)\n",
    "        max_words = 0\n",
    "        for sentence in sentence_arr:\n",
    "            word_count = self.word_count(sentence)\n",
    "            if word_count > max_words:\n",
    "                max_words = word_count\n",
    "\n",
    "        return max_words\n",
    "\n",
    "def textstats_is_not_whitespace(word):\n",
    "    \"\"\"Utility method for filter to filter out blank words\"\"\"\n",
    "    if len(re.sub(\"[^aeiouy]+\", \"\", word)) > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_readability(comment_text):\n",
    "    textstat = TextStatistics(\"\")\n",
    "    text = comment_text.lower()\n",
    "\n",
    "    #filter out punctuations\n",
    "    punctuations = string.punctuation # includes following characters: !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\n",
    "    excluded_punctuations = [\"$\", \"%\", \"'\"]\n",
    "    for p in punctuations:\n",
    "        if p not in excluded_punctuations:\n",
    "            text = text.replace(p, \" \")\n",
    "\n",
    "    readability_score = textstat.smog_index(text=text)\n",
    "    return readability_score\n",
    "\n",
    "\n",
    "def calcPersonalXPScores(comment_text):\n",
    "    # comment_text = comment_text.decode(\"utf-8\")\n",
    "    # tokenizer = WhitespaceTokenizer()\n",
    "    personal_xp_score = 0\n",
    "    text = comment_text.lower()\n",
    "\n",
    "    #filter out punctuations\n",
    "    punctuations = string.punctuation # includes following characters: !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\n",
    "    excluded_punctuations = [\"$\", \"%\", \"'\"]\n",
    "    for p in punctuations:\n",
    "        if p not in excluded_punctuations:\n",
    "            text = text.replace(p, \" \")\n",
    "\n",
    "    # tokenize it\n",
    "    token_list = nltk.word_tokenize(comment_text)\n",
    "    text_tokens = token_list\n",
    "    # comment_stemmed_tokens = [porter.stem(token) for token in token_list]\n",
    "    # if the tokens are in the personal_words List then increment score\n",
    "    for tok in text_tokens:\n",
    "        tok_stem = porter.stem(tok)\n",
    "#         print(tok, tok_stem)\n",
    "        if tok_stem in personal_words:\n",
    "            personal_xp_score = personal_xp_score + 1\n",
    "\n",
    "    # normalize by number of tokens\n",
    "#     print(len(text_tokens), personal_xp_score)\n",
    "    if len(text_tokens) > 0:\n",
    "        personal_xp_score = float(personal_xp_score) / float(len(text_tokens))\n",
    "#         print(personal_xp_score)\n",
    "    else:\n",
    "        personal_xp_score = 0.0\n",
    "    return personal_xp_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18a84f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(source):\n",
    "    dataset = pd.DataFrame(source['summary'].unique())\n",
    "    dataset['summary'] = dataset[0]\n",
    "    dataset = dataset.drop(0, 1)\n",
    "    dataset['readability'] = dataset.apply(lambda row: get_readability(row['summary']), axis=1)\n",
    "    dataset['personal_description'] = dataset.apply(lambda row: calcPersonalXPScores(row['summary']), axis=1)\n",
    "    dataset['tokens'] = dataset.apply(lambda row: nltk.word_tokenize(row['summary']), axis = 1)\n",
    "    dataset['spell_check'] = dataset.apply(lambda row: len(spellchk.unknown(row['tokens'])), axis = 1)\n",
    "    dataset['ner_count'] = dataset['summary'].apply(lambda row: len(nlp(row).ents))\n",
    "    dataset['unequal'] = dataset.apply(lambda row: (row['spell_check'], row['ner_count']), axis=1)\n",
    "    dataset['act_spell_check'] = dataset.apply(lambda row: row['unequal'][0] - row['unequal'][1], axis=1)\n",
    "    dataset['act_spell_check'] = dataset.apply(lambda row: 0 if row['act_spell_check'] < 0 else row['act_spell_check'], axis=1)\n",
    "    dataset = dataset.drop(['spell_check', 'unequal'], 1)\n",
    "    dataset.rename(columns = {'act_spell_check':'spell_check'}, inplace = True)\n",
    "    count = lambda l1,l2: sum([1 for x in l1 if x in l2])\n",
    "    dataset['punctuation'] = dataset.apply(lambda row: count(row['summary'],set(string.punctuation)), axis = 1)\n",
    "    source = source.drop(['ner_count'], 1)\n",
    "    source = dataset.merge(source, on='summary')\n",
    "    source = source.drop(['Unnamed: 0'], 1)\n",
    "    source['length'] = source.apply(lambda row: np.array([row['full_text_average_word_length'], row['full_text_sentences_mean_word_count'], len(row['full_text_tokens']), len(row['full_text_sentences'])]), axis=1)\n",
    "    source['quality'] = source.apply(lambda row: np.array([row['personal_description'], row['readability'], row['punctuation'], row['spell_check']]), axis=1)\n",
    "    return source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "837ccfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-32be62c04170>:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  dataset = dataset.drop(0, 1)\n",
      "<ipython-input-8-32be62c04170>:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  dataset = dataset.drop(['spell_check', 'unequal'], 1)\n",
      "<ipython-input-8-32be62c04170>:17: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  source = source.drop(['ner_count'], 1)\n",
      "<ipython-input-8-32be62c04170>:19: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  source = source.drop(['Unnamed: 0'], 1)\n"
     ]
    }
   ],
   "source": [
    "train_features = get_dataframe(train)\n",
    "test_features = get_dataframe(test)\n",
    "val_features = get_dataframe(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a602f3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_svm(attribute):\n",
    "    svm = sklearn.svm.SVC(kernel='linear', class_weight='balanced')\n",
    "    if len(np.array(list(train_features[attribute])).shape) < 2:\n",
    "        X =  np.array(list(train_features[attribute])).reshape((-1, 1))\n",
    "    else:\n",
    "        X =  np.array(list(train_features[attribute]))\n",
    "    y =  np.array(list(train_features['output']))\n",
    "    scaling = np.array(list(train_features['scaling']))\n",
    "    svm.fit(X, y, sample_weight=scaling)\n",
    "    if len(np.array(list(train_features[attribute])).shape) < 2:\n",
    "        accuracy = svm.score(np.array(list(test_features[attribute])).reshape((-1,1)), np.array(list(test['output'])))\n",
    "    else:\n",
    "        accuracy = svm.score(np.array(list(test_features[attribute])), np.array(list(test['output'])))\n",
    "    if len(np.array(list(train_features[attribute])).shape) < 2:\n",
    "        y_pred = svm.predict(np.array(list(test_features[attribute])).reshape((-1,1)))\n",
    "    else:\n",
    "        y_pred = svm.predict(np.array(list(test_features[attribute])))\n",
    "    f1 = sklearn.metrics.f1_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    precision = sklearn.metrics.precision_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    recall = sklearn.metrics.recall_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    avg_precision = sklearn.metrics.average_precision_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    return f'SVM: {attribute}, accuracy: {accuracy}, f1: {f1}, precision: {precision}, recall: {recall}, average precision: {avg_precision}, roc_auc: {roc_auc}'\n",
    "\n",
    "def get_metrics_log_reg(attribute):\n",
    "    logreg = LogisticRegression(class_weight='balanced')\n",
    "    if len(np.array(list(train_features[attribute])).shape) < 2:\n",
    "        X =  np.array(list(train_features[attribute])).reshape((-1, 1))\n",
    "    else:\n",
    "        X =  np.array(list(train_features[attribute]))\n",
    "    y =  np.array(list(train_features['output']))\n",
    "    scaling = np.array(list(train_features['scaling']))\n",
    "    logreg.fit(X, y, sample_weight=scaling)\n",
    "    if len(np.array(list(train_features[attribute])).shape) < 2:\n",
    "        accuracy = logreg.score(np.array(list(test_features[attribute])).reshape((-1,1)), np.array(list(test['output'])))\n",
    "    else:\n",
    "        accuracy = logreg.score(np.array(list(test_features[attribute])), np.array(list(test['output'])))\n",
    "    if len(np.array(list(train_features[attribute])).shape) < 2:\n",
    "        y_pred = logreg.predict(np.array(list(test_features[attribute])).reshape((-1,1)))\n",
    "    else:\n",
    "        y_pred = logreg.predict(np.array(list(test_features[attribute])))\n",
    "    f1 = sklearn.metrics.f1_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    precision = sklearn.metrics.precision_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    recall = sklearn.metrics.recall_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    avg_precision = sklearn.metrics.average_precision_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    return f'Logistic Regression: {attribute}, accuracy: {accuracy}, f1: {f1}, precision: {precision}, recall: {recall}, average precision: {avg_precision}, roc_auc: {roc_auc}'\n",
    "\n",
    "def get_metrics_rf(attribute):\n",
    "    seed = 50\n",
    "    rf = RandomForestClassifier(\n",
    "                      min_samples_leaf=50,\n",
    "                      n_estimators=1500,\n",
    "                      bootstrap=True,\n",
    "                      oob_score=True,\n",
    "                      n_jobs=-1,\n",
    "                      random_state=seed,\n",
    "                      max_features='auto',\n",
    "                      class_weight='balanced')\n",
    "    if len(np.array(list(train_features[attribute])).shape) < 2:\n",
    "        X =  np.array(list(train_features[attribute])).reshape((-1, 1))\n",
    "    else:\n",
    "        X =  np.array(list(train_features[attribute]))\n",
    "    y =  np.array(list(train_features['output']))\n",
    "    scaling = np.array(list(train_features['scaling']))\n",
    "    rf.fit(X, y, sample_weight=scaling)\n",
    "    if len(np.array(list(train_features[attribute])).shape) < 2:\n",
    "        accuracy = rf.score(np.array(list(test_features[attribute])).reshape((-1,1)), np.array(list(test['output'])))\n",
    "    else:\n",
    "        accuracy = rf.score(np.array(list(test_features[attribute])), np.array(list(test['output'])))\n",
    "    if len(np.array(list(train_features[attribute])).shape) < 2:\n",
    "        y_pred = rf.predict(np.array(list(test_features[attribute])).reshape((-1,1)))\n",
    "    else:\n",
    "        y_pred = rf.predict(np.array(list(test_features[attribute])))\n",
    "    f1 = sklearn.metrics.f1_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    precision = sklearn.metrics.precision_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    recall = sklearn.metrics.recall_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    avg_precision = sklearn.metrics.average_precision_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    return f'Random Forest: {attribute}, accuracy: {accuracy}, f1: {f1}, precision: {precision}, recall: {recall}, average precision: {avg_precision}, roc_auc: {roc_auc}'\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "faecb4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: ner_count, accuracy: 0.414771104977634, f1: 0.35446524013483055, precision: 0.7135805140955456, recall: 0.23579796909871645, average precision: 0.6587610614224928, roc_auc: 0.5330920837908776\n",
      "Logistic Regression: ner_count, accuracy: 0.4505567716760255, f1: 0.48264882537735443, precision: 0.6882557610583585, recall: 0.3716295979749051, average precision: 0.6590934124364873, roc_auc: 0.5349838616481061\n"
     ]
    }
   ],
   "source": [
    "print(get_metrics_svm('ner_count'))\n",
    "print(get_metrics_log_reg('ner_count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1177cd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: quality, accuracy: 0.48500999333777484, f1: 0.5362098717793582, precision: 0.7275435539965197, recall: 0.42455729713131396, average precision: 0.6782296790345478, roc_auc: 0.569814379845463\n",
      "Logistic Regression: quality, accuracy: 0.5407823355857999, f1: 0.6199120524096, precision: 0.7159046177743338, recall: 0.5466183528536525, average precision: 0.6823279234696285, roc_auc: 0.5789411730726411\n"
     ]
    }
   ],
   "source": [
    "print(get_metrics_svm('quality'))\n",
    "print(get_metrics_log_reg('quality'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "23d8ab14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: length, accuracy: 0.5441134481774056, f1: 0.6406678702564477, precision: 0.7221161181632643, recall: 0.5757306011017966, average precision: 0.6880600792380256, roc_auc: 0.5893439664382519\n",
      "Logistic Regression: length, accuracy: 0.5263157894736842, f1: 0.6058176037263575, precision: 0.7187743254108871, recall: 0.5235420043067095, average precision: 0.6821213397823485, roc_auc: 0.5782247605197893\n"
     ]
    }
   ],
   "source": [
    "print(get_metrics_svm('length'))\n",
    "print(get_metrics_log_reg('length'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7505eada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: ner_count, accuracy: 0.5389740173217855, f1: 0.6210280988035914, precision: 0.6779465488416294, recall: 0.572926805548559, average precision: 0.6625290887494052, roc_auc: 0.5425906959663964\n",
      "Random Forest: quality, accuracy: 0.5861806414771105, f1: 0.6989372390151177, precision: 0.7248917088342361, recall: 0.6747771034358027, average precision: 0.6978834316701904, roc_auc: 0.6079203892582593\n",
      "Random Forest: length, accuracy: 0.5840867992766727, f1: 0.6936877068383339, precision: 0.702266679930583, recall: 0.6853158076136804, average precision: 0.6832533329955931, roc_auc: 0.5823138397947051\n"
     ]
    }
   ],
   "source": [
    "print(get_metrics_rf('ner_count'))\n",
    "print(get_metrics_rf('quality'))\n",
    "print(get_metrics_rf('length'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0fd60231",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features['all'] = train_features.apply(lambda row: list(itertools.chain(row['length'], row['quality'], [row['ner_count']])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a02e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features['all'] = test_features.apply(lambda row: list(itertools.chain(row['length'], row['quality'], [row['ner_count']])), axis=1)\n",
    "val_features['all'] = val_features.apply(lambda row: list(itertools.chain(row['length'], row['quality'], [row['ner_count']])), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbdba7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/arunas/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: all, accuracy: 0.5213667079090131, f1: 0.606418347113234, precision: 0.7260169289183717, recall: 0.520650319711153, average precision: 0.6856697519501522, roc_auc: 0.5842676014642383\n"
     ]
    }
   ],
   "source": [
    "print(get_metrics_log_reg('all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a747e099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: all, accuracy: 0.5891310554868183, f1: 0.7190539202051455, precision: 0.7216845120406783, recall: 0.7164424361125497, average precision: 0.6990457754945192, roc_auc: 0.6106484654921459\n"
     ]
    }
   ],
   "source": [
    "print(get_metrics_rf('all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3037d684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: all, accuracy: 0.5374512229941943, f1: 0.6268917145829604, precision: 0.7232104405399724, recall: 0.5532135421272645, average precision: 0.6868580323605471, roc_auc: 0.5868884060201726\n"
     ]
    }
   ],
   "source": [
    "print(get_metrics_svm('all'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
