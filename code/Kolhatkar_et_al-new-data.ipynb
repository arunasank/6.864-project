{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dd9cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "435e5a37",
   "metadata": {},
   "source": [
    "# Kolhatkar et al parallels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "594ca83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install simpledorff\n",
    "# !pip3 install krippendorff\n",
    "# !pip3 install nltk\n",
    "# !pip3 install py-readability-metrics\n",
    "# !pip3 uninstall spacy -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fff2372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 uninstall spacy -y\n",
    "# !pip3 install spacy\n",
    "# # !pip3 uninstall spacy-transformers -y\n",
    "# # !pip3 install spacy_readability\n",
    "# !python3 -m spacy download en_core_web_sm\n",
    "# !pip3 install spacy-transformers\n",
    "# !pip3 uninstall manual_spellchecker -y\n",
    "# !pip3 uninstall autocorrect -y\n",
    "# !pip3 uninstall spellchecker -y\n",
    "# !pip3 install pyspellchecker\n",
    "# !pip3 install sklearn-pandas\n",
    "# !pip3 install tqdm>=4.61.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ec870a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.10\n",
      "\u001b[33mWARNING: The directory '/u/arunas/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /u/arunas/.local/lib/python3.8/site-packages (4.62.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 --version\n",
    "!pip3 install tqdm --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7f60064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-_75e2q84 because the default path (/u/arunas/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n",
      "<ipython-input-4-cc521505c3c5>:31: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tqdm_notebook().pandas()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43b7eaa32cf46d0a10c497bf7a2fc64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /u/arunas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import simpledorff\n",
    "import krippendorff\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import spacy\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from spellchecker import SpellChecker\n",
    "import sklearn_pandas\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "\n",
    "spellchk = SpellChecker()\n",
    "\n",
    "# tqdm.pandas()\n",
    "tqdm_notebook().pandas()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ae111ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train-mod.csv')\n",
    "test = pd.read_csv('../data/test-mod.csv')\n",
    "val = pd.read_csv('../data/val-mod.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49049d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_dataframe(dataset):\n",
    "    dataset_ratings = dataset.filter(regex=('author_id|participantId|noteId|output|scaling|tweet_text|summary'))\n",
    "    dataset_ratings = dataset_ratings.groupby(['noteId', 'participantId', 'summary', 'tweet_text', 'tweet_author_id']).size().to_frame(name = 'count').reset_index().merge(dataset_ratings)\n",
    "    dataset_ratings['full_text'] = dataset_ratings.apply(lambda row: f'<BEG> {row[\"tweet_text\"]} <SEP> {row[\"summary\"]} <END>', axis=1)\n",
    "    dataset_unique = pd.DataFrame(dataset_ratings['full_text'].unique())\n",
    "    dataset_unique['full_text'] = dataset_unique[0]\n",
    "    dataset_unique = dataset_unique.drop(0, 1)\n",
    "    dataset_unique['ner_count'] = dataset_unique['full_text'].apply(lambda row: len(nlp(row).ents))\n",
    "    dataset_ratings = pd.merge(dataset_ratings, dataset_unique, on='full_text')\n",
    "    dataset_ratings['full_text_tokens'] = dataset_ratings.apply(lambda row: nltk.word_tokenize(row['full_text']), axis=1)\n",
    "    dataset_ratings['full_text_average_word_length'] = dataset_ratings.apply(lambda row: np.mean([len(token) for token in row['full_text_tokens']]), axis=1)\n",
    "    dataset_ratings[\"full_text_sentences\"] = dataset_ratings.apply(lambda row: nltk.sent_tokenize(row['full_text']), axis=1)\n",
    "    dataset_ratings['full_text_sentences_mean_word_count'] = dataset_ratings.apply(lambda row: np.mean([len(sentence.split(' ')) for sentence in row['full_text_sentences']]), axis=1)\n",
    "    return dataset_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95b5bbd",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a8f5127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import string\n",
    "\n",
    "porter = nltk.PorterStemmer()\n",
    "with open(\"../data/personal.txt\") as f:\n",
    "    personal_words = f.read().splitlines()\n",
    "\n",
    "class TextStatistics(object):\n",
    "    '''\n",
    "    classdocs\n",
    "    '''\n",
    "\n",
    "\n",
    "    def __init__(self, text):\n",
    "        '''\n",
    "        Constructor\n",
    "        '''\n",
    "        self.text = self.clean_text(text)\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        if text is None:\n",
    "            return self.text\n",
    "\n",
    "        full_stop_tags = ['li', 'p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'dd']\n",
    "\n",
    "        for tag_name in full_stop_tags:\n",
    "            text = text.replace(\"</%s>\" % tag_name, \".\")\n",
    "\n",
    "        \"\"\"\n",
    "        Regular expressions that are to be replaced\n",
    "        \"\"\"\n",
    "        replacement_expressions = [ [\"<[^>]+>\", \"\"], #Strip tags\n",
    "                                   [\"[,:;()\\\\-]\", \" \"],  #Replace commas, hyphens etc (count them as spaces)\n",
    "                                   [\"[\\\\.!?]\", \".\"], #unify terminators\n",
    "                                   [\"^\\\\s+\", \"\"], #strip leading whitespace\n",
    "                                   [\"[ ]*(\\\\n|\\\\r\\\\n|\\\\r)[ ]*\", \" \"], #Replace new lines with spaces\n",
    "                                   [\"([\\\\.])[\\\\. ]+\", \".\"],#check for duplicated terminators\n",
    "                                   [\"[ ]*([\\\\.])\", \". \"], #Pad sentence terminators\n",
    "                                   [\"\\\\s+\", \" \"], #Remove multiple spaces\n",
    "                                   [\"\\\\s+$\", \"\"]] #strip trailing white space\n",
    "\n",
    "        for replacement_set in replacement_expressions:\n",
    "            text = re.compile(replacement_set[0]).sub(\n",
    "                                          replacement_set[1], text)\n",
    "\n",
    "        #Add final terminator in case it's missing.\n",
    "        if len(text) > 0 and text[-1] != '.':\n",
    "            text += '.'\n",
    "\n",
    "        return text\n",
    "\n",
    "    def flesch_kincaid_reading_ease(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "        return round((206.835 - (1.015 * self.average_words_per_sentence(text)) - (84.6 * self.average_syllables_per_word(text)))*10)/10\n",
    "\n",
    "    def flesch_kincaid_grade_level(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "        return round(((0.39 * self.average_words_per_sentence(text)) + (11.8 * self.average_syllables_per_word(text)) - 15.59)*10)/10\n",
    "\n",
    "    def gunning_fog_score(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "        return round(((self.average_words_per_sentence(text) + self.percentage_words_with_three_syllables(text, False)) * 0.4)*10)/10\n",
    "\n",
    "    def coleman_liau_index(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "        return round(((5.89 * (self.letter_count(text) / self.word_count(text))) - (0.3 * (self.sentence_count(text) / self.word_count(text))) - 15.8 ) *10)/10\n",
    "\n",
    "    def smog_index(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "        return round(1.043 * math.sqrt((self.words_with_three_syllables(text) * (30 / self.sentence_count(text))) + 3.1291)*10)/10\n",
    "\n",
    "    def automated_readability_index(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "        return round(((4.71 * (self.letter_count(text) / self.word_count(text))) + (0.5 * (self.word_count(text) / self.sentence_count(text))) - 21.43)*10)/10;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def syllable_count(self, word):\n",
    "        syllable_count = 0\n",
    "        prefix_suffix_count = 0\n",
    "        word_part_count = 0\n",
    "\n",
    "        word = word.lower()\n",
    "        word = re.compile(\"[^a-z]\").sub(\"\", word)\n",
    "\n",
    "        problem_words = {\n",
    "            \"simile\":        3,\n",
    "            \"forever\":        3,\n",
    "            \"shoreline\":    2\n",
    "        }\n",
    "\n",
    "        if word in problem_words:\n",
    "            return problem_words[word]\n",
    "\n",
    "        #These syllables would be counted as two but should be one\n",
    "        sub_syllables = [\n",
    "            \"cial\",\n",
    "            \"tia\",\n",
    "            \"cius\",\n",
    "            \"cious\",\n",
    "            \"giu\",\n",
    "            \"ion\",\n",
    "            \"iou\",\n",
    "            \"sia$\",\n",
    "            \"[^aeiuoyt]{2,}ed$\",\n",
    "            \".ely$/\",\n",
    "            \"[cg]h?e[rsd]?$\",\n",
    "            \"rved?$\",\n",
    "            \"[aeiouy][dt]es?$\",\n",
    "            \"[aeiouy][^aeiouydt]e[rsd]?$\",\n",
    "            \"^[dr]e[aeiou][^aeiou]+$\", # Sorts out deal, deign etc\n",
    "            \"[aeiouy]rse$\" # Purse, hearse\n",
    "        ]\n",
    "\n",
    "        #These syllables would be counted as one but should be two\n",
    "        add_syllables = [\n",
    "            \"ia\",\n",
    "            \"riet\",\n",
    "            \"dien\",\n",
    "            \"iu\",\n",
    "            \"io\",\n",
    "            \"ii\",\n",
    "            \"[aeiouym]bl$\",\n",
    "            \"[aeiou]{3}\",\n",
    "            \"^mc\",\n",
    "            \"ism$\",\n",
    "            \"([^aeiouy])\\\\1l$\",\n",
    "            \"[^l]lien\",\n",
    "            \"^coa[dglx].\",\n",
    "            \"[^gq]ua[^auieo]/\",\n",
    "            \"dnt$\",\n",
    "            \"uity$\",\n",
    "            \"ie(r|st)$\"\n",
    "        ]\n",
    "\n",
    "        # Single syllable prefixes and suffixes\n",
    "        prefix_suffix = [\n",
    "            \"^un\",\n",
    "            \"^fore\",\n",
    "            \"ly$\",\n",
    "            \"less$\",\n",
    "            \"ful$\",\n",
    "            \"ers?$\",\n",
    "            \"ings?$\"\n",
    "        ]\n",
    "\n",
    "        #Remove prefixes and suffixes and count how many were taken\n",
    "        for current_prefix_suffix in prefix_suffix:\n",
    "            pattern = re.compile(current_prefix_suffix)\n",
    "            if pattern.match(word) is not None:\n",
    "                word = pattern.sub(\"\", word)\n",
    "                prefix_suffix_count = prefix_suffix_count + 1\n",
    "\n",
    "        word_parts = list(filter(textstats_is_not_whitespace,\n",
    "                             re.split(\"[^aeiouy]+\", word)))\n",
    "\n",
    "        word_part_count = len(word_parts)\n",
    "        x = 5\n",
    "\n",
    "        syllable_count = word_part_count + prefix_suffix_count\n",
    "        for current_sub in sub_syllables:\n",
    "            if re.match(current_sub, word) is not None:\n",
    "                syllable_count = syllable_count - 1\n",
    "\n",
    "        for current_sub in add_syllables:\n",
    "            if re.match(current_sub, word) is not None:\n",
    "                syllable_count = syllable_count + 1\n",
    "\n",
    "        return max(syllable_count, 1)\n",
    "\n",
    "    def text_length(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "        return len(text)\n",
    "\n",
    "    def letter_count(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "        #strangely - re.IGNORECASE will leave the last . on text\n",
    "        repl = re.sub(\"[^a-z|A-Z]+\", \"\", text)\n",
    "        return len(repl)\n",
    "\n",
    "\n",
    "    def sentence_count(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "        text = re.sub(\"[^\\\\.!?]\", \"\", text)\n",
    "        return max(len(text), 1)\n",
    "\n",
    "    def words_with_three_syllables(self, text = None, count_proper_nouns = True):\n",
    "        text = self.clean_text(text)\n",
    "        long_word_count = 0\n",
    "\n",
    "        word_parts = re.split(\"s+\", text)\n",
    "        for word in word_parts:\n",
    "            # We don't count proper nouns or capitalised words if the countProperNouns attribute is set.\n",
    "            #Defaults to true.\n",
    "            if re.match(\"^[A-Z]\", text) is None or count_proper_nouns:\n",
    "                if self.syllable_count(word) > 2:\n",
    "                    long_word_count += 1\n",
    "\n",
    "        return long_word_count\n",
    "\n",
    "    def percentage_words_with_three_syllables(self, text = None, count_proper_nouns = True):\n",
    "        text = self.clean_text(text)\n",
    "        return self.words_with_three_syllables(text, count_proper_nouns) / self.word_count(text)\n",
    "\n",
    "    def word_count(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "\n",
    "        #In case of a zero length item... split will return an array of length 1\n",
    "        if len(text) == 0:\n",
    "            return 0\n",
    "\n",
    "        return len(self.get_words(text))\n",
    "\n",
    "    def get_words(self, cleaned_text):\n",
    "        return re.split(\"[^a-zA-Z0-9]+\",cleaned_text)\n",
    "\n",
    "    def get_distinct_words(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "        word_arr = re.split(\"[^a-zA-Z0-9]+\", text)\n",
    "        distinct_word_arr = []\n",
    "        for word in word_arr:\n",
    "            word = word.lower()\n",
    "            word = re.sub(\"[^a-zA-Z]\",\"\", word)\n",
    "            if word not in distinct_word_arr:\n",
    "                distinct_word_arr.append(word)\n",
    "\n",
    "        return distinct_word_arr\n",
    "\n",
    "    def word_count_distinct(self, text = None):\n",
    "        \"\"\"Count the number of distinct different words\"\"\"\n",
    "        word_arr = self.get_distinct_words(text)\n",
    "        return len(word_arr)\n",
    "\n",
    "\n",
    "\n",
    "    def average_syllables_per_word(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "\n",
    "        syllable_count = 0\n",
    "        word_count = self.word_count(text)\n",
    "        word_arr = self.get_words(text)\n",
    "        for word in word_arr:\n",
    "            syllable_count += self.syllable_count(word)\n",
    "\n",
    "        return float(max(syllable_count, 1)) / float(max(word_count, 1))\n",
    "\n",
    "    def max_syllables_per_word(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "\n",
    "        max_value = 0\n",
    "        word_arr = self.get_words(text)\n",
    "        for word in word_arr:\n",
    "            num_syllables = self.syllable_count(word)\n",
    "            if num_syllables > max_value:\n",
    "                max_value = num_syllables\n",
    "\n",
    "        return max_value\n",
    "\n",
    "\n",
    "    def average_words_per_sentence(self, text = None):\n",
    "        text = self.clean_text(text)\n",
    "        return float(self.word_count(text)) / float(self.sentence_count(text))\n",
    "\n",
    "    def max_words_per_sentence(self, text = None):\n",
    "        #split into sentences\n",
    "        text = self.clean_text(text)\n",
    "        sentence_arr = re.split(\"[\\\\.!?]\", text)\n",
    "        max_words = 0\n",
    "        for sentence in sentence_arr:\n",
    "            word_count = self.word_count(sentence)\n",
    "            if word_count > max_words:\n",
    "                max_words = word_count\n",
    "\n",
    "        return max_words\n",
    "\n",
    "def textstats_is_not_whitespace(word):\n",
    "    \"\"\"Utility method for filter to filter out blank words\"\"\"\n",
    "    if len(re.sub(\"[^aeiouy]+\", \"\", word)) > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_readability(comment_text):\n",
    "    textstat = TextStatistics(\"\")\n",
    "    text = comment_text.lower()\n",
    "\n",
    "    #filter out punctuations\n",
    "    punctuations = string.punctuation # includes following characters: !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\n",
    "    excluded_punctuations = [\"$\", \"%\", \"'\"]\n",
    "    for p in punctuations:\n",
    "        if p not in excluded_punctuations:\n",
    "            text = text.replace(p, \" \")\n",
    "\n",
    "    readability_score = textstat.smog_index(text=text)\n",
    "    return readability_score\n",
    "\n",
    "\n",
    "def calcPersonalXPScores(comment_text):\n",
    "    # comment_text = comment_text.decode(\"utf-8\")\n",
    "    # tokenizer = WhitespaceTokenizer()\n",
    "    personal_xp_score = 0\n",
    "    text = comment_text.lower()\n",
    "\n",
    "    #filter out punctuations\n",
    "    punctuations = string.punctuation # includes following characters: !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\n",
    "    excluded_punctuations = [\"$\", \"%\", \"'\"]\n",
    "    for p in punctuations:\n",
    "        if p not in excluded_punctuations:\n",
    "            text = text.replace(p, \" \")\n",
    "\n",
    "    # tokenize it\n",
    "    token_list = nltk.word_tokenize(comment_text)\n",
    "    text_tokens = token_list\n",
    "    # comment_stemmed_tokens = [porter.stem(token) for token in token_list]\n",
    "    # if the tokens are in the personal_words List then increment score\n",
    "    for tok in text_tokens:\n",
    "        tok_stem = porter.stem(tok)\n",
    "#         print(tok, tok_stem)\n",
    "        if tok_stem in personal_words:\n",
    "            personal_xp_score = personal_xp_score + 1\n",
    "\n",
    "    # normalize by number of tokens\n",
    "#     print(len(text_tokens), personal_xp_score)\n",
    "    if len(text_tokens) > 0:\n",
    "        personal_xp_score = float(personal_xp_score) / float(len(text_tokens))\n",
    "#         print(personal_xp_score)\n",
    "    else:\n",
    "        personal_xp_score = 0.0\n",
    "    return personal_xp_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18a84f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(source):\n",
    "    dataset = pd.DataFrame(source['summary'].unique())\n",
    "    dataset['summary'] = dataset[0]\n",
    "    dataset = dataset.drop(0, 1)\n",
    "    dataset['readability'] = dataset.apply(lambda row: get_readability(row['summary']), axis=1)\n",
    "    dataset['personal_description'] = dataset.apply(lambda row: calcPersonalXPScores(row['summary']), axis=1)\n",
    "    dataset['tokens'] = dataset.apply(lambda row: nltk.word_tokenize(row['summary']), axis = 1)\n",
    "    dataset['spell_check'] = dataset.apply(lambda row: len(spellchk.unknown(row['tokens'])), axis = 1)\n",
    "    dataset['ner_count'] = dataset['summary'].apply(lambda row: len(nlp(row).ents))\n",
    "    dataset['unequal'] = dataset.apply(lambda row: (row['spell_check'], row['ner_count']), axis=1)\n",
    "    dataset['act_spell_check'] = dataset.apply(lambda row: row['unequal'][0] - row['unequal'][1], axis=1)\n",
    "    dataset['act_spell_check'] = dataset.apply(lambda row: 0 if row['act_spell_check'] < 0 else row['act_spell_check'], axis=1)\n",
    "    dataset = dataset.drop(['spell_check', 'unequal'], 1)\n",
    "    dataset.rename(columns = {'act_spell_check':'spell_check'}, inplace = True)\n",
    "    count = lambda l1,l2: sum([1 for x in l1 if x in l2])\n",
    "    dataset['punctuation'] = dataset.apply(lambda row: count(row['summary'],set(string.punctuation)), axis = 1)\n",
    "    source = source.drop(['ner_count'], 1)\n",
    "    source = dataset.merge(source, on='summary')\n",
    "    source = source.drop(['Unnamed: 0'], 1)\n",
    "    source['length'] = source.apply(lambda row: np.array([row['full_text_average_word_length'], row['full_text_sentences_mean_word_count'], len(row['full_text_tokens']), len(row['full_text_sentences'])]), axis=1)\n",
    "    source['quality'] = source.apply(lambda row: np.array([row['personal_description'], row['readability'], row['punctuation'], row['spell_check']]), axis=1)\n",
    "    return source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c4d107f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-8d64b86bb9fd>:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  train_unique = train_unique.drop(0, 1)\n"
     ]
    }
   ],
   "source": [
    "train_unique = pd.DataFrame(train['summary'].unique())\n",
    "train_unique['summary'] = train_unique[0]\n",
    "train_unique = train_unique.drop(0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f6c7459",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unique['readability'] = train_unique.apply(lambda row: get_readability(row['summary']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad4eaabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unique['personal_description'] = train_unique.apply(lambda row: calcPersonalXPScores(row['summary']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dac68ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_unique['personal_description'].astype(bool).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43ccfeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def autospell(text):\n",
    "#     tokens = (nltk.word_tokenize(text))\n",
    "#     spells = [spell(w) for w in tokens]\n",
    "#     return np.where(spells != tokens)[0].size\n",
    "    \n",
    "# train_unique['spell checks'] = train_unique.apply(lambda row: autospell(row['summary']), axis=1)\n",
    "\n",
    "train_unique['tokens'] = train_unique.apply(lambda row: nltk.word_tokenize(row['summary']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "295d1c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unique['spell_check'] = train_unique.apply(lambda row: len(spellchk.unknown(row['tokens'])), axis = 1)\n",
    "\n",
    "# print(spell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fa29fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unique['ner_count'] = train_unique['summary'].apply(lambda row: len(nlp(row).ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97e719eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unique['unequal'] = train_unique.apply(lambda row: (row['spell_check'], row['ner_count']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "448cd649",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unique['act_spell_check'] = train_unique.apply(lambda row: row['unequal'][0] - row['unequal'][1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19c703e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unique['act_spell_check'] = train_unique.apply(lambda row: 0 if row['act_spell_check'] < 0 else row['act_spell_check'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76551ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-b1114bdf9d98>:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  train_unique = train_unique.drop(['spell_check', 'unequal'], 1)\n"
     ]
    }
   ],
   "source": [
    "train_unique = train_unique.drop(['spell_check', 'unequal'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f516dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unique.rename(columns = {'act_spell_check':'spell_check'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f932a575",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = lambda l1,l2: sum([1 for x in l1 if x in l2])\n",
    "train_unique['punctuation'] = train_unique.apply(lambda row: count(row['summary'],set(string.punctuation)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8b33f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-3431f776c892>:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  train = train.drop(['ner_count'], 1)\n"
     ]
    }
   ],
   "source": [
    "train = train.drop(['ner_count'], 1)\n",
    "train_features = train_unique.merge(train, on='summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b051c206",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-7224c0f61c24>:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  train_features = train_features.drop(['Unnamed: 0'], 1)\n"
     ]
    }
   ],
   "source": [
    "train_features = train_features.drop(['Unnamed: 0'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "462a39bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features['length'] = train_features.apply(lambda row: np.array([row['full_text_average_word_length'], row['full_text_sentences_mean_word_count'], len(row['full_text_tokens']), len(row['full_text_sentences'])]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "628841a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features['quality'] = train_features.apply(lambda row: np.array([row['personal_description'], row['readability'], row['punctuation'], row['spell_check']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9da58852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['summary', 'readability', 'personal_description', 'tokens', 'ner_count',\n",
       "       'spell_check', 'punctuation', 'noteId', 'participantId', 'tweet_text',\n",
       "       'tweet_author_id', 'count', 'output', 'scaling', 'full_text',\n",
       "       'full_text_tokens', 'full_text_average_word_length',\n",
       "       'full_text_sentences', 'full_text_sentences_mean_word_count', 'length',\n",
       "       'quality'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "837ccfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-32be62c04170>:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  dataset = dataset.drop(0, 1)\n",
      "<ipython-input-8-32be62c04170>:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  dataset = dataset.drop(['spell_check', 'unequal'], 1)\n",
      "<ipython-input-8-32be62c04170>:17: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  source = source.drop(['ner_count'], 1)\n",
      "<ipython-input-8-32be62c04170>:19: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  source = source.drop(['Unnamed: 0'], 1)\n"
     ]
    }
   ],
   "source": [
    "test_features = get_dataframe(test)\n",
    "val_features = get_dataframe(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "256c29ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Unnamed: 0', 'noteId', 'participantId', 'summary', 'tweet_text',\n",
       "        'tweet_author_id', 'count', 'output', 'scaling', 'full_text',\n",
       "        'ner_count', 'full_text_tokens', 'full_text_average_word_length',\n",
       "        'full_text_sentences', 'full_text_sentences_mean_word_count'],\n",
       "       dtype='object'),\n",
       " Index(['Unnamed: 0', 'noteId', 'participantId', 'summary', 'tweet_text',\n",
       "        'tweet_author_id', 'count', 'output', 'scaling', 'full_text',\n",
       "        'ner_count', 'full_text_tokens', 'full_text_average_word_length',\n",
       "        'full_text_sentences', 'full_text_sentences_mean_word_count'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns, val.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a1fcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = sklearn.svm.SVC(kernel='linear', verbose=1)\n",
    "X =  np.array(list(train_features['length']))\n",
    "y =  np.array(list(train_features['output']))\n",
    "print(type(X), type(y))\n",
    "scaling = np.array(list(train_features['scaling']))\n",
    "clf.fit(X, y, sample_weight=scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c72e064",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(np.array(list(test_features['length'])), np.array(list(test_features['output'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0014f955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(verbose=1)\n",
    "logreg.fit(X, y, sample_weight=scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1176584b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6603216903017036"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(np.array(list(test_features['length'])), np.array(list(test_features['output'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94f8d833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', verbose=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = sklearn.svm.SVC(kernel='linear', verbose=1)\n",
    "X1 =  np.array(list(train_features['quality']))\n",
    "y =  np.array(list(train_features['output']))\n",
    "print(type(X1), type(y))\n",
    "scaling = np.array(list(train_features['scaling']))\n",
    "clf.fit(X1, y, sample_weight=scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95d1cd43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6603216903017036"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(np.array(list(test_features['quality'])), np.array(list(test['output'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60e64963",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(verbose=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(verbose=1)\n",
    "logreg.fit(X1, y, sample_weight=scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6711711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6706005520129438"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(np.array(list(test_features['quality'])), np.array(list(test['output'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "304a77f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', verbose=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = sklearn.svm.SVC(kernel='linear', verbose=1)\n",
    "X2 =  np.array(list(train_features['ner_count'])).reshape((-1, 1))\n",
    "y =  np.array(list(train_features['output']))\n",
    "print(type(X2), type(y))\n",
    "scaling = np.array(list(train_features['scaling']))\n",
    "clf.fit(X2, y, sample_weight=scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db3e704d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6603216903017036"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(np.array(list(test_features['ner_count'])).reshape((-1, 1)), np.array(list(test['output'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f7df4251",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(verbose=1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(verbose=1)\n",
    "logreg.fit(X2, y, sample_weight=scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a1e0203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6603216903017036"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(np.array(list(test_features['ner_count'])).reshape((-1, 1)), np.array(list(test['output'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6669afde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> (88185, 1) (88185,)\n",
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', verbose=1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = sklearn.svm.SVC(kernel='linear', verbose=1)\n",
    "X2 =  np.array(list(train_features['ner_count'])).reshape((-1, 1))\n",
    "y =  np.array(list(train_features['output']))\n",
    "print(type(X2), type(y), X2.shape, y.shape)\n",
    "scaling = np.array(list(train_features['scaling']))\n",
    "clf.fit(X2, y, sample_weight=scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4b359218",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.ones(test['output'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "917ba3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6603216903017036"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predictions == test['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "83497bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([31347.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0., 56838.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_features['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b46ab8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3569.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "        6938.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test_features['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7df7c285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4170.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "        7471.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(val_features['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75931eec",
   "metadata": {},
   "source": [
    "# With class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6863add9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(class_weight='balanced', kernel='linear', verbose=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_length = sklearn.svm.SVC(kernel='linear', verbose=True, class_weight='balanced')\n",
    "X =  np.array(list(train_features['length']))\n",
    "y =  np.array(list(train_features['output']))\n",
    "print(type(X), type(y))\n",
    "scaling = np.array(list(train_features['scaling']))\n",
    "clf_length.fit(X, y, sample_weight=scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "53491f4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 4 features, but SVC is expecting 1 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-a08774289086>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \"\"\"\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m             X = self._validate_data(\n\u001b[0m\u001b[1;32m    593\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                 \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    396\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 4 features, but SVC is expecting 1 features as input."
     ]
    }
   ],
   "source": [
    "y_pred = clf_length.predict(np.array(list(test_features['length'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2915dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54677833825069"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_length.score(np.array(list(test_features['length'])), np.array(list(test_features['output'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8bb30078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg_length = LogisticRegression(class_weight='balanced')\n",
    "logreg_length.fit(X, y, sample_weight=scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1a5e1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.530122775292662"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_length.score(np.array(list(test_features['length'])), np.array(list(test_features['output'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "581a0236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(class_weight='balanced', kernel='linear')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_quality = sklearn.svm.SVC(kernel='linear', class_weight='balanced')\n",
    "X1 =  np.array(list(train_features['quality']))\n",
    "y =  np.array(list(train_features['output']))\n",
    "print(type(X1), type(y))\n",
    "scaling = np.array(list(train_features['scaling']))\n",
    "clf_quality.fit(X1, y, sample_weight=scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "367c6ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48500999333777484"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_quality.score(np.array(list(test_features['quality'])), np.array(list(test['output'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0946bba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg_quality = LogisticRegression(class_weight='balanced')\n",
    "logreg_quality.fit(X1, y, sample_weight=scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03521d45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5407823355857999"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_quality.score(np.array(list(test_features['quality'])), np.array(list(test['output'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e50e08b",
   "metadata": {},
   "outputs": [],
   "source": [
    " y_logreg_quality_pred = logreg_quality.predict(np.array(list(test_features['ner_count'])).reshape((-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c555b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48264882537735443"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " sklearn.metrics.f1_score(test_features['output'], y_logreg_quality_pred, sample_weight=test_features['scaling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "494f9d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6882557610583585"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.precision_score(test_features['output'], y_logreg_quality_pred, sample_weight=test_features['scaling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "25cfe73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3716295979749051"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.recall_score(test_features['output'], y_logreg_quality_pred, sample_weight=test_features['scaling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "487cc12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6590934124364873"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.average_precision_score(test_features['output'], y_logreg_quality_pred, sample_weight=test_features['scaling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "70aea59f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5349838616481061"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.roc_auc_score(test_features['output'], y_logreg_quality_pred, sample_weight=test_features['scaling'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63adc14",
   "metadata": {},
   "source": [
    "# NER COUNT - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5cacd5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(class_weight='balanced', kernel='linear')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_ner_count = sklearn.svm.SVC(kernel='linear', class_weight='balanced')\n",
    "X2 =  np.array(list(train_features['ner_count'])).reshape((-1, 1))\n",
    "y =  np.array(list(train_features['output']))\n",
    "print(type(X2), type(y))\n",
    "scaling = np.array(list(train_features['scaling']))\n",
    "clf_ner_count.fit(X2, y, sample_weight=scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ca9cb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.414771104977634"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_ner_count.score(np.array(list(test_features['ner_count'])).reshape((-1, 1)), np.array(list(test['output'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7fe9dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    " y_svm_ner_count_pred = logreg_ner_count.predict(np.array(list(test_features['ner_count'])).reshape((-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13083594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48264882537735443"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " sklearn.metrics.f1_score(test_features['output'], y_svm_ner_count_pred, sample_weight=test_features['scaling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "345005cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6882557610583585"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.precision_score(test_features['output'], y_svm_ner_count_pred, sample_weight=test_features['scaling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "babaf135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3716295979749051"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.recall_score(test_features['output'], y_svm_ner_count_pred, sample_weight=test_features['scaling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "562d2a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6590934124364873"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.average_precision_score(test_features['output'], y_svm_ner_count_pred, sample_weight=test_features['scaling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d1944a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5349838616481061"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.roc_auc_score(test_features['output'], y_svm_ner_count_pred, sample_weight=test_features['scaling'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13e5415",
   "metadata": {},
   "source": [
    "# NER COUNT - LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "de73ab9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_ner_count = LogisticRegression(class_weight='balanced')\n",
    "logreg_ner_count.fit(X2, y, sample_weight=scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "94597c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4505567716760255"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_ner_count.score(np.array(list(test_features['ner_count'])).reshape((-1, 1)), np.array(list(test['output'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a71a299d",
   "metadata": {},
   "outputs": [],
   "source": [
    " y_logreg_ner_count_pred = logreg_ner_count.predict(np.array(list(test_features['ner_count'])).reshape((-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "720c5007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48264882537735443"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " sklearn.metrics.f1_score(test_features['output'], y_logreg_ner_count_pred, sample_weight=test_features['scaling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db1eb264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6882557610583585"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.precision_score(test_features['output'], y_logreg_ner_count_pred, sample_weight=test_features['scaling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb096f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3716295979749051"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.recall_score(test_features['output'], y_logreg_ner_count_pred, sample_weight=test_features['scaling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0e5f9d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6590934124364873"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.average_precision_score(test_features['output'], y_logreg_ner_count_pred, sample_weight=test_features['scaling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f72263bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5349838616481061"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.roc_auc_score(test_features['output'], y_logreg_ner_count_pred, sample_weight=test_features['scaling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a602f3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_svm(attribute):\n",
    "    svm = sklearn.svm.SVC(kernel='linear', class_weight='balanced')\n",
    "    if len(np.array(list(train_features[attribute])).shape) < 2:\n",
    "        X =  np.array(list(train_features[attribute])).reshape((-1, 1))\n",
    "    else:\n",
    "        X =  np.array(list(train_features[attribute]))\n",
    "    y =  np.array(list(train_features['output']))\n",
    "    scaling = np.array(list(train_features['scaling']))\n",
    "    svm.fit(X, y, sample_weight=scaling)\n",
    "    if len(np.array(list(train_features[attribute])).shape) < 2:\n",
    "        accuracy = svm.score(np.array(list(test_features[attribute])).reshape((-1,1)), np.array(list(test['output'])))\n",
    "    else:\n",
    "        accuracy = svm.score(np.array(list(test_features[attribute])), np.array(list(test['output'])))\n",
    "    if len(np.array(list(train_features[attribute])).shape) < 2:\n",
    "        y_pred = svm.predict(np.array(list(test_features[attribute])).reshape((-1,1)))\n",
    "    else:\n",
    "        y_pred = svm.predict(np.array(list(test_features[attribute])))\n",
    "    f1 = sklearn.metrics.f1_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    precision = sklearn.metrics.precision_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    recall = sklearn.metrics.recall_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    avg_precision = sklearn.metrics.average_precision_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    return f'SVM: {attribute}, accuracy: {accuracy}, f1: {f1}, precision: {precision}, recall: {recall}, average precision: {avg_precision}, roc_auc: {roc_auc}'\n",
    "\n",
    "def get_metrics_log_reg(attribute):\n",
    "    logreg = LogisticRegression(class_weight='balanced')\n",
    "    if len(np.array(list(train_features[attribute])).shape) < 2:\n",
    "        X =  np.array(list(train_features[attribute])).reshape((-1, 1))\n",
    "    else:\n",
    "        X =  np.array(list(train_features[attribute]))\n",
    "    y =  np.array(list(train_features['output']))\n",
    "    scaling = np.array(list(train_features['scaling']))\n",
    "    logreg.fit(X, y, sample_weight=scaling)\n",
    "    if len(np.array(list(train_features[attribute])).shape) < 2:\n",
    "        accuracy = logreg.score(np.array(list(test_features[attribute])).reshape((-1,1)), np.array(list(test['output'])))\n",
    "    else:\n",
    "        accuracy = logreg.score(np.array(list(test_features[attribute])), np.array(list(test['output'])))\n",
    "    if len(np.array(list(train_features[attribute])).shape) < 2:\n",
    "        y_pred = logreg.predict(np.array(list(test_features[attribute])).reshape((-1,1)))\n",
    "    else:\n",
    "        y_pred = logreg.predict(np.array(list(test_features[attribute])))\n",
    "    f1 = sklearn.metrics.f1_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    precision = sklearn.metrics.precision_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    recall = sklearn.metrics.recall_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    avg_precision = sklearn.metrics.average_precision_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    return f'Logistic Regression: {attribute}, accuracy: {accuracy}, f1: {f1}, precision: {precision}, recall: {recall}, average precision: {avg_precision}, roc_auc: {roc_auc}'\n",
    "\n",
    "def get_metrics_rf(attribute):\n",
    "    seed = 50\n",
    "    rf = RandomForestClassifier(\n",
    "                      min_samples_leaf=50,\n",
    "                      n_estimators=1500,\n",
    "                      bootstrap=True,\n",
    "                      oob_score=True,\n",
    "                      n_jobs=-1,\n",
    "                      random_state=seed,\n",
    "                      max_features='auto',\n",
    "                      class_weight='balanced')\n",
    "    if len(np.array(list(train_features[attribute])).shape) < 2:\n",
    "        X =  np.array(list(train_features[attribute])).reshape((-1, 1))\n",
    "    else:\n",
    "        X =  np.array(list(train_features[attribute]))\n",
    "    y =  np.array(list(train_features['output']))\n",
    "    scaling = np.array(list(train_features['scaling']))\n",
    "    rf.fit(X, y, sample_weight=scaling)\n",
    "    if len(np.array(list(train_features[attribute])).shape) < 2:\n",
    "        accuracy = rf.score(np.array(list(test_features[attribute])).reshape((-1,1)), np.array(list(test['output'])))\n",
    "    else:\n",
    "        accuracy = rf.score(np.array(list(test_features[attribute])), np.array(list(test['output'])))\n",
    "    if len(np.array(list(train_features[attribute])).shape) < 2:\n",
    "        y_pred = rf.predict(np.array(list(test_features[attribute])).reshape((-1,1)))\n",
    "    else:\n",
    "        y_pred = rf.predict(np.array(list(test_features[attribute])))\n",
    "    f1 = sklearn.metrics.f1_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    precision = sklearn.metrics.precision_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    recall = sklearn.metrics.recall_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    avg_precision = sklearn.metrics.average_precision_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(test_features['output'], y_pred, sample_weight=test_features['scaling'])\n",
    "    return f'Random Forest: {attribute}, accuracy: {accuracy}, f1: {f1}, precision: {precision}, recall: {recall}, average precision: {avg_precision}, roc_auc: {roc_auc}'\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "faecb4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: ner_count, accuracy: 0.414771104977634, f1: 0.35446524013483055, precision: 0.7135805140955456, recall: 0.23579796909871645, average precision: 0.6587610614224928, roc_auc: 0.5330920837908776\n",
      "Logistic Regression: ner_count, accuracy: 0.4505567716760255, f1: 0.48264882537735443, precision: 0.6882557610583585, recall: 0.3716295979749051, average precision: 0.6590934124364873, roc_auc: 0.5349838616481061\n"
     ]
    }
   ],
   "source": [
    "print(get_metrics_svm('ner_count'))\n",
    "print(get_metrics_log_reg('ner_count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1177cd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: quality, accuracy: 0.48500999333777484, f1: 0.5362098717793582, precision: 0.7275435539965197, recall: 0.42455729713131396, average precision: 0.6782296790345478, roc_auc: 0.569814379845463\n",
      "Logistic Regression: quality, accuracy: 0.5407823355857999, f1: 0.6199120524096, precision: 0.7159046177743338, recall: 0.5466183528536525, average precision: 0.6823279234696285, roc_auc: 0.5789411730726411\n"
     ]
    }
   ],
   "source": [
    "print(get_metrics_svm('quality'))\n",
    "print(get_metrics_log_reg('quality'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "23d8ab14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: length, accuracy: 0.5441134481774056, f1: 0.6406678702564477, precision: 0.7221161181632643, recall: 0.5757306011017966, average precision: 0.6880600792380256, roc_auc: 0.5893439664382519\n",
      "Logistic Regression: length, accuracy: 0.5263157894736842, f1: 0.6058176037263575, precision: 0.7187743254108871, recall: 0.5235420043067095, average precision: 0.6821213397823485, roc_auc: 0.5782247605197893\n"
     ]
    }
   ],
   "source": [
    "print(get_metrics_svm('length'))\n",
    "print(get_metrics_log_reg('length'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7505eada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: ner_count, accuracy: 0.5389740173217855, f1: 0.6210280988035914, precision: 0.6779465488416294, recall: 0.572926805548559, average precision: 0.6625290887494052, roc_auc: 0.5425906959663964\n",
      "Random Forest: quality, accuracy: 0.5861806414771105, f1: 0.6989372390151177, precision: 0.7248917088342361, recall: 0.6747771034358027, average precision: 0.6978834316701904, roc_auc: 0.6079203892582593\n",
      "Random Forest: length, accuracy: 0.5840867992766727, f1: 0.6936877068383339, precision: 0.702266679930583, recall: 0.6853158076136804, average precision: 0.6832533329955931, roc_auc: 0.5823138397947051\n"
     ]
    }
   ],
   "source": [
    "print(get_metrics_rf('ner_count'))\n",
    "print(get_metrics_rf('quality'))\n",
    "print(get_metrics_rf('length'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0fd60231",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features['all'] = train_features.apply(lambda row: list(itertools.chain(row['length'], row['quality'], [row['ner_count']])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a02e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features['all'] = test_features.apply(lambda row: list(itertools.chain(row['length'], row['quality'], [row['ner_count']])), axis=1)\n",
    "val_features['all'] = val_features.apply(lambda row: list(itertools.chain(row['length'], row['quality'], [row['ner_count']])), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbdba7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/arunas/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: all, accuracy: 0.5213667079090131, f1: 0.606418347113234, precision: 0.7260169289183717, recall: 0.520650319711153, average precision: 0.6856697519501522, roc_auc: 0.5842676014642383\n"
     ]
    }
   ],
   "source": [
    "print(get_metrics_log_reg('all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a747e099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: all, accuracy: 0.5891310554868183, f1: 0.7190539202051455, precision: 0.7216845120406783, recall: 0.7164424361125497, average precision: 0.6990457754945192, roc_auc: 0.6106484654921459\n"
     ]
    }
   ],
   "source": [
    "print(get_metrics_rf('all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3037d684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: all, accuracy: 0.5374512229941943, f1: 0.6268917145829604, precision: 0.7232104405399724, recall: 0.5532135421272645, average precision: 0.6868580323605471, roc_auc: 0.5868884060201726\n"
     ]
    }
   ],
   "source": [
    "print(get_metrics_svm('all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed02bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
