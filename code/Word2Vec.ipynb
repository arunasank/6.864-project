{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a9bd4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/u/arunas/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: gensim in /u/arunas/.local/lib/python3.8/site-packages (4.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/lib/python3/dist-packages (from gensim) (1.17.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /u/arunas/.local/lib/python3.8/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.5.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a535872f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/u/arunas/6.864/code\r\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import pprint\n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim.models as models\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "from decimal import Decimal\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b21a52f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train_split_v1.csv')\n",
    "test = pd.read_csv('../data/test_split_v1.csv')\n",
    "val = pd.read_csv('../data/val_split_v1.csv')\n",
    "\n",
    "tweets = pd.read_csv('../data/tweet_text2021-11-04.csv')\n",
    "notes = pd.read_csv('../data/notes-00000.tsv', sep='\\t')\n",
    "ratings = pd.read_csv('../data/ratings-00000.tsv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "feac5d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12688, 1587, 1586)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['tweetId', 'title']\n",
    "len(train.index), len(test.index), len(val.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "81083044",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = train[['noteId', 'tweetId', 'summary']].join(tweets[['id', 'text']].set_index('id'), on='tweetId', how='left', lsuffix='_x', rsuffix='_y')\n",
    "test = test[['noteId', 'tweetId', 'summary']].join(tweets[['id', 'text']].set_index('id'), on='tweetId', how='left', lsuffix='_x', rsuffix='_y')\n",
    "val = val[['noteId', 'tweetId', 'summary']].join(tweets[['id', 'text']].set_index('id'), on='tweetId', how='left', lsuffix='_x', rsuffix='_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "40a12cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12688 1587 1586\n",
      "Index(['noteId', 'tweetId', 'summary', 'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(len(train.index), len(test.index), len(val.index))\n",
    "print(train.columns)\n",
    "\n",
    "# train.columns, test.columns, val.columns\n",
    "# len(train.index), len(test.index), len(val.index)\n",
    "# train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9438f204",
   "metadata": {},
   "source": [
    "# Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b38df11d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['noteId', 'participantId', 'createdAtMillis', 'version', 'agree',\n",
       "       'disagree', 'helpful', 'notHelpful', 'helpfulnessLevel', 'helpfulOther',\n",
       "       'helpfulInformative', 'helpfulClear', 'helpfulEmpathetic',\n",
       "       'helpfulGoodSources', 'helpfulUniqueContext', 'helpfulAddressesClaim',\n",
       "       'helpfulImportantContext', 'notHelpfulOther', 'notHelpfulIncorrect',\n",
       "       'notHelpfulSourcesMissingOrUnreliable',\n",
       "       'notHelpfulOpinionSpeculationOrBias', 'notHelpfulMissingKeyPoints',\n",
       "       'notHelpfulOutdated', 'notHelpfulHardToUnderstand',\n",
       "       'notHelpfulArgumentativeOrInflammatory', 'notHelpfulOffTopic',\n",
       "       'notHelpfulSpamHarassmentOrAbuse', 'notHelpfulIrrelevantSources'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2ce83268",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_subset = ratings[['noteId', 'helpfulnessLevel']].dropna()\n",
    "\n",
    "helpful_dict = {'HELPFUL' : 1, 'NOT_HELPFUL': 0, 'SOMEWHAT_HELPFUL': 0.5}\n",
    "ratings_subset['label'] = ratings_subset['helpfulnessLevel'].apply(lambda x: helpful_dict[x])\n",
    "\n",
    "ratings_subset = ratings_subset.groupby('noteId')['label'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "76b09bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5296 626 681\n",
      "Index(['noteId', 'tweetId', 'summary', 'text', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train = train.join(ratings_subset.set_index('noteId'), on='noteId', how='inner', lsuffix='_x', rsuffix='_y')\n",
    "test = test.join(ratings_subset.set_index('noteId'), on='noteId', how='inner', lsuffix='_x', rsuffix='_y')\n",
    "val = val.join(ratings_subset.set_index('noteId'), on='noteId', how='inner', lsuffix='_x', rsuffix='_y')\n",
    "\n",
    "print(len(train.index), len(test.index), len(val.index))\n",
    "print(train.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c23cc60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tweet_note']=[(f\"<SEP>{tweet}<SEP_BW>{note}</SEP>\", label) for tweet, note, label in zip(train['text'], train['summary'], train['label'])]\n",
    "test['tweet_note']=[(f\"<SEP>{tweet}<SEP_BW>{note}</SEP>\", label) for tweet, note, label in zip(test['text'], test['summary'], test['label'])]\n",
    "val['tweet_note']=[(f\"<SEP>{tweet}<SEP_BW>{note}</SEP>\", label) for tweet, note, label in zip(val['text'], val['summary'], val['label'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "59ce12df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 23:42:11,676 : INFO : collecting document frequencies\n",
      "2021-11-14 23:42:11,678 : INFO : PROGRESS: processing document #0\n",
      "2021-11-14 23:42:11,787 : INFO : TfidfModel lifecycle event {'msg': 'calculated IDF weights for 5296 documents and 21298 features (286258 matrix non-zeros)', 'datetime': '2021-11-14T23:42:11.787283', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'initialize'}\n"
     ]
    }
   ],
   "source": [
    "documents = [doc[0] for doc in train['tweet_note']]\n",
    "label = [int(doc[1] > 0) for doc in train['tweet_note']]\n",
    "# label = label/np.linalg.norm(label)\n",
    "documents_tokenized = [simple_preprocess(doc) for doc in documents]\n",
    "dictionary = corpora.Dictionary()\n",
    "BoW_corpus = [dictionary.doc2bow(doc, allow_update=True) for doc in documents_tokenized]\n",
    "tfidf = models.TfidfModel(BoW_corpus, smartirs='ntc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "503d2833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SEP>CDC is arm of DNC.<SEP_BW>This is a lie. CDC's parent agency is the United States Department of Health and Human Services https://www.cdc.gov/about/organization/cio.htm</SEP> [(0, 0.08988692622437675), (1, 0.24566794428290145), (2, 0.020446296995960414), (3, 0.28351854836142576), (4, 0.4003297759648584), (5, 0.37182060431521463), (6, 0.2040974617016572), (7, 0.32859469269146535), (8, 0.09615205747374914), (9, 0.11769958344217324), (10, 0.23291702855313706), (11, 0.005631047851479717), (12, 0.18727136156904245), (13, 0.053834621105222795), (14, 0.1611418940090403), (15, 0.040645640829613465), (16, 0.22708555416381293), (17, 0.33912146448232344), (18, 1.7813607861185632e-05), (19, 8.906803930592816e-06), (20, 0.21633987299230467), (21, 0.12632217753872652), (22, 0.005882594181078636), (23, 0.04249244820027498), (24, 0.1659919202521891), (25, 0.030481089841312876)]\n"
     ]
    }
   ],
   "source": [
    "BoW_list = list(tfidf[BoW_corpus])\n",
    "print(documents[0], BoW_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954f7934",
   "metadata": {},
   "source": [
    "# Determining the stop word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "35c24dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.0\n"
     ]
    }
   ],
   "source": [
    "sentence_lengths = [len(doc) for doc in tfidf[BoW_corpus]]\n",
    "sent_len = np.percentile(sentence_lengths, 95)\n",
    "print(sent_len)\n",
    "stop_list = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3ea7bf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in', 'with', 'they', 'are', 'evidence', 'out', 'trump', 'to', 'that', 'sense', 're', 'we', 'don', 'www', 'on', 'or', 'get', 'yes', 'back', 'you', 'your', 'longer', 'from', 'about', 'at', 'no', 'https', 'of', 'if', 'men', 'it', 'fact', 'than', 'sep_bw', 'tweet', 'people', 'joke', 'and', 'like', 'west', 'for', 'self', 'theft', 'because', 'real', 'covid', 'clearly', 'off', 'an', 'by', 'org', 'did', 'co', 'sep', 'the', 'is', 'com', 'not', 'he', 'have', 'would', 'has', 'this', 'weeks', 'biden', 'was', 'gov', 'as', 'coronavirus', 'who', 'be', 'cdc'}\n"
     ]
    }
   ],
   "source": [
    "for doc in tfidf[BoW_corpus]:\n",
    "    doc.sort(key=lambda x: x[1])\n",
    "    a = [dictionary[word[0]] for word in doc[:5]]\n",
    "    stop_list.update(a)\n",
    "\n",
    "print(stop_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc69efa2",
   "metadata": {},
   "source": [
    "# Doc2Vec -- get embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "597c2d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 19:58:33,147 : INFO : collecting all words and their counts\n",
      "2021-11-12 19:58:33,148 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-11-12 19:58:33,238 : INFO : collected 21298 word types from a corpus of 369656 raw words and 5296 sentences\n",
      "2021-11-12 19:58:33,240 : INFO : Creating a fresh vocabulary\n",
      "2021-11-12 19:58:33,332 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 21298 unique words (100.0%% of original 21298, drops 0)', 'datetime': '2021-11-12T19:58:33.332330', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "2021-11-12 19:58:33,333 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 369656 word corpus (100.0%% of original 369656, drops 0)', 'datetime': '2021-11-12T19:58:33.333364', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "2021-11-12 19:58:33,503 : INFO : deleting the raw counts dictionary of 21298 items\n",
      "2021-11-12 19:58:33,504 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2021-11-12 19:58:33,505 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 291919.821169497 word corpus (79.0%% of prior 369656)', 'datetime': '2021-11-12T19:58:33.505533', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "2021-11-12 19:58:33,819 : INFO : estimated required memory for 21298 words and 81 dimensions: 24450104 bytes\n",
      "2021-11-12 19:58:33,820 : INFO : resetting layer weights\n",
      "2021-11-12 19:58:33,839 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-11-12T19:58:33.839939', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'build_vocab'}\n",
      "2021-11-12 19:58:33,841 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 21298 vocabulary and 81 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2021-11-12T19:58:33.841317', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'train'}\n",
      "2021-11-12 19:58:34,082 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 19:58:34,088 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 19:58:34,093 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 19:58:34,097 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 19:58:34,098 : INFO : EPOCH - 1 : training on 369656 raw words (292139 effective words) took 0.2s, 1169083 effective words/s\n",
      "2021-11-12 19:58:34,339 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 19:58:34,343 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 19:58:34,348 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 19:58:34,352 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 19:58:34,353 : INFO : EPOCH - 2 : training on 369656 raw words (292085 effective words) took 0.3s, 1166759 effective words/s\n",
      "2021-11-12 19:58:34,591 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 19:58:34,596 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 19:58:34,602 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 19:58:34,607 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 19:58:34,608 : INFO : EPOCH - 3 : training on 369656 raw words (291839 effective words) took 0.3s, 1158987 effective words/s\n",
      "2021-11-12 19:58:34,880 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 19:58:34,883 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 19:58:34,891 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 19:58:34,895 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 19:58:34,896 : INFO : EPOCH - 4 : training on 369656 raw words (292025 effective words) took 0.3s, 1024324 effective words/s\n",
      "2021-11-12 19:58:35,144 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 19:58:35,145 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 19:58:35,149 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 19:58:35,160 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 19:58:35,161 : INFO : EPOCH - 5 : training on 369656 raw words (291971 effective words) took 0.3s, 1114710 effective words/s\n",
      "2021-11-12 19:58:35,162 : INFO : Word2Vec lifecycle event {'msg': 'training on 1848280 raw words (1460059 effective words) took 1.3s, 1106576 effective words/s', 'datetime': '2021-11-12T19:58:35.161985', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'train'}\n",
      "2021-11-12 19:58:35,162 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=21298, vector_size=81, alpha=0.025)', 'datetime': '2021-11-12T19:58:35.162582', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'created'}\n",
      "2021-11-12 19:58:35,165 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'word2vec.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2021-11-12T19:58:35.165247', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'saving'}\n",
      "2021-11-12 19:58:35,166 : INFO : not storing attribute cum_table\n",
      "2021-11-12 19:58:35,378 : INFO : saved word2vec.model\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences=documents_tokenized, vector_size=int(sent_len), window=10, min_count=1, workers=4)\n",
    "documents[0], documents_tokenized[0]\n",
    "\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "73496a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('president', 0.9502883553504944),\n",
       " ('joe', 0.9487913250923157),\n",
       " ('trump', 0.941845715045929),\n",
       " ('delaware', 0.9114742279052734),\n",
       " ('provision', 0.9030532836914062),\n",
       " ('electors', 0.9025029540061951),\n",
       " ('kamala', 0.8874210119247437),\n",
       " ('donald', 0.8859433531761169),\n",
       " ('hunter', 0.8781907558441162),\n",
       " ('pompeo', 0.8768683671951294)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = model.wv['biden']\n",
    "sims = model.wv.most_similar('biden', topn=10)\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2e9ed6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 19:58:40,216 : INFO : collecting all words and their counts\n",
      "2021-11-12 19:58:40,217 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2021-11-12 19:58:40,303 : INFO : collected 21298 word types and 5296 unique tags from a corpus of 5296 examples and 369656 words\n",
      "2021-11-12 19:58:40,304 : INFO : Creating a fresh vocabulary\n",
      "2021-11-12 19:58:40,395 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 21298 unique words (100.0%% of original 21298, drops 0)', 'datetime': '2021-11-12T19:58:40.395791', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "2021-11-12 19:58:40,396 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 369656 word corpus (100.0%% of original 369656, drops 0)', 'datetime': '2021-11-12T19:58:40.396471', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "2021-11-12 19:58:40,566 : INFO : deleting the raw counts dictionary of 21298 items\n",
      "2021-11-12 19:58:40,567 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2021-11-12 19:58:40,568 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 291919.821169497 word corpus (79.0%% of prior 369656)', 'datetime': '2021-11-12T19:58:40.568391', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "2021-11-12 19:58:40,879 : INFO : estimated required memory for 21298 words and 81 dimensions: 27225208 bytes\n",
      "2021-11-12 19:58:40,880 : INFO : resetting layer weights\n",
      "2021-11-12 19:58:40,900 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 21298 vocabulary and 81 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2021-11-12T19:58:40.900175', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'train'}\n",
      "2021-11-12 19:58:41,625 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 19:58:41,626 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 19:58:41,632 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 19:58:41,655 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 19:58:41,656 : INFO : EPOCH - 1 : training on 369656 raw words (297122 effective words) took 0.8s, 394667 effective words/s\n",
      "2021-11-12 19:58:42,422 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 19:58:42,424 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 19:58:42,448 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 19:58:42,451 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 19:58:42,451 : INFO : EPOCH - 2 : training on 369656 raw words (297424 effective words) took 0.8s, 375382 effective words/s\n",
      "2021-11-12 19:58:43,227 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 19:58:43,231 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 19:58:43,234 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 19:58:43,269 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 19:58:43,269 : INFO : EPOCH - 3 : training on 369656 raw words (297141 effective words) took 0.8s, 364634 effective words/s\n",
      "2021-11-12 19:58:44,006 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 19:58:44,012 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 19:58:44,017 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 19:58:44,042 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 19:58:44,042 : INFO : EPOCH - 4 : training on 369656 raw words (297131 effective words) took 0.8s, 386147 effective words/s\n",
      "2021-11-12 19:58:44,834 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 19:58:44,838 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 19:58:44,845 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 19:58:44,862 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 19:58:44,863 : INFO : EPOCH - 5 : training on 369656 raw words (297385 effective words) took 0.8s, 363867 effective words/s\n",
      "2021-11-12 19:58:45,614 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 19:58:45,618 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 19:58:45,624 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 19:58:45,644 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 19:58:45,645 : INFO : EPOCH - 6 : training on 369656 raw words (297213 effective words) took 0.8s, 381676 effective words/s\n",
      "2021-11-12 19:58:46,439 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 19:58:46,444 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 19:58:46,450 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 19:58:46,474 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 19:58:46,475 : INFO : EPOCH - 7 : training on 369656 raw words (297359 effective words) took 0.8s, 359505 effective words/s\n",
      "2021-11-12 19:58:47,257 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 19:58:47,259 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 19:58:47,263 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 19:58:47,288 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 19:58:47,289 : INFO : EPOCH - 8 : training on 369656 raw words (297277 effective words) took 0.8s, 367087 effective words/s\n",
      "2021-11-12 19:58:48,091 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 19:58:48,097 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 19:58:48,128 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 19:58:48,131 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 19:58:48,131 : INFO : EPOCH - 9 : training on 369656 raw words (297331 effective words) took 0.8s, 354399 effective words/s\n",
      "2021-11-12 19:58:48,908 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 19:58:48,918 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 19:58:48,923 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 19:58:48,943 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 19:58:48,944 : INFO : EPOCH - 10 : training on 369656 raw words (296900 effective words) took 0.8s, 367523 effective words/s\n",
      "2021-11-12 19:58:48,944 : INFO : Doc2Vec lifecycle event {'msg': 'training on 3696560 raw words (2972283 effective words) took 8.0s, 369511 effective words/s', 'datetime': '2021-11-12T19:58:48.944857', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'train'}\n",
      "2021-11-12 19:58:48,945 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec(dm/m,d81,n5,w10,s0.001,t4)', 'datetime': '2021-11-12T19:58:48.945474', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(documents_tokenized)]\n",
    "model = Doc2Vec(documents, vector_size=int(sent_len), window=10, min_count=1, workers=4)\n",
    "\n",
    "# common_texts, documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0cf310a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 19:58:48,952 : INFO : Doc2Vec lifecycle event {'fname_or_handle': '/tmp/tmpwu_bnr08/doc2vec_tweets_notes', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2021-11-12T19:58:48.952191', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'saving'}\n",
      "2021-11-12 19:58:48,952 : INFO : not storing attribute cum_table\n",
      "2021-11-12 19:58:48,982 : INFO : saved /tmp/tmpwu_bnr08/doc2vec_tweets_notes\n",
      "2021-11-12 19:58:48,983 : INFO : loading Doc2Vec object from /tmp/tmpwu_bnr08/doc2vec_tweets_notes\n",
      "2021-11-12 19:58:48,996 : INFO : loading dv recursively from /tmp/tmpwu_bnr08/doc2vec_tweets_notes.dv.* with mmap=None\n",
      "2021-11-12 19:58:48,997 : INFO : loading wv recursively from /tmp/tmpwu_bnr08/doc2vec_tweets_notes.wv.* with mmap=None\n",
      "2021-11-12 19:58:48,998 : INFO : setting ignored attribute cum_table to None\n",
      "2021-11-12 19:58:49,359 : INFO : Doc2Vec lifecycle event {'fname': '/tmp/tmpwu_bnr08/doc2vec_tweets_notes', 'datetime': '2021-11-12T19:58:49.359718', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import get_tmpfile\n",
    "fname = get_tmpfile(\"doc2vec_tweets_notes\")\n",
    "model.save(fname)\n",
    "\n",
    "model = Doc2Vec.load(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60014c6",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a19e4b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as torch_data\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "918a78aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(label)):\n",
    "#     print(label[i])\n",
    "data = [(torch.from_numpy((model.infer_vector(documents_tokenized[i]))).float().unsqueeze(1), int(label[i])) for i in range(len(documents_tokenized))]\n",
    "\n",
    "print(type(data[0][0]), type(data[0][1]))\n",
    "# print(data[0], data[0].shape)\n",
    "# print(data[1], data[1].shape)\n",
    "# print(data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "91b9d8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2')  # run on colab gpu\n",
    "\n",
    "# class NeuralNetwork(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(NeuralNetwork, self).__init__()\n",
    "#         self.flatten = nn.Flatten()\n",
    "#         self.linear_relu_stack = nn.Sequential(\n",
    "#             nn.Linear(81, 40),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(40, 40),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(40, 1),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.to(device)\n",
    "#         x = self.flatten(x)\n",
    "#         logits = self.linear_relu_stack(x)\n",
    "#         return logits\n",
    "\n",
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.squeeze(0)\n",
    "        outputs = torch.sigmoid(self.linear(x.T))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cd561d31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:34<00:00, 14.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34.98855006694794, 32.501944959163666, 30.62615019083023, 29.24514675140381, 28.20510596036911, 27.40751326084137, 26.783091634511948, 26.27863672375679, 25.868837594985962, 25.524880290031433, 25.235499262809753, 24.984737932682037, 24.76930332183838, 24.581441909074783, 24.41574537754059, 24.268038481473923, 24.135708063840866, 24.017120629549026, 23.90847772359848, 23.809518069028854, 23.721173495054245, 23.639677226543427, 23.56456595659256, 23.496120363473892, 23.429496496915817, 23.370623648166656, 23.313936978578568, 23.259805411100388, 23.213137477636337, 23.16669636964798, 23.122585117816925, 23.082998543977737, 23.043576329946518, 23.00527858734131, 22.972083568572998, 22.93942102789879, 22.907775729894638, 22.879473447799683, 22.851094156503677, 22.82430651783943, 22.800704032182693, 22.774579912424088, 22.750482887029648, 22.72758713364601, 22.705737620592117, 22.6850728392601, 22.667626291513443, 22.64545527100563, 22.628178030252457, 22.610565096139908, 22.592923313379288, 22.57541537284851, 22.561375975608826, 22.543486416339874, 22.531918227672577, 22.516407042741776, 22.500500798225403, 22.487163215875626, 22.47694766521454, 22.462245494127274, 22.450134098529816, 22.437617510557175, 22.429509788751602, 22.417505979537964, 22.405568957328796, 22.396750032901764, 22.384506434202194, 22.37628021836281, 22.366638123989105, 22.356983244419098, 22.346281737089157, 22.337781876325607, 22.329237043857574, 22.320439517498016, 22.313588112592697, 22.305406272411346, 22.297220766544342, 22.29025274515152, 22.282707571983337, 22.276652604341507, 22.26958280801773, 22.262410193681717, 22.258187264204025, 22.248984456062317, 22.245015263557434, 22.235290437936783, 22.23119729757309, 22.2254056930542, 22.218949407339096, 22.215273529291153, 22.207389295101166, 22.20409604907036, 22.198439598083496, 22.194625973701477, 22.189608067274094, 22.18506196141243, 22.177576571702957, 22.172714293003082, 22.167509973049164, 22.163940578699112, 22.16063004732132, 22.15648126602173, 22.15077644586563, 22.14720442891121, 22.14399591088295, 22.140917092561722, 22.137860476970673, 22.13171562552452, 22.13012856245041, 22.12505117058754, 22.123042792081833, 22.11772060394287, 22.113554924726486, 22.110164284706116, 22.10994529724121, 22.105048418045044, 22.103352278470993, 22.099906384944916, 22.09534603357315, 22.092625826597214, 22.088838905096054, 22.087375342845917, 22.0850547850132, 22.079532146453857, 22.080740332603455, 22.077761471271515, 22.0750832259655, 22.07333767414093, 22.069251537322998, 22.0669949054718, 22.06514060497284, 22.063251972198486, 22.062012881040573, 22.06073036789894, 22.057397186756134, 22.054910868406296, 22.05219539999962, 22.048977434635162, 22.04844030737877, 22.04812401533127, 22.045899480581284, 22.04408425092697, 22.040275365114212, 22.039406061172485, 22.039445102214813, 22.03526771068573, 22.035764157772064, 22.034218311309814, 22.03234001994133, 22.02992680668831, 22.02974534034729, 22.027473896741867, 22.024818122386932, 22.024310678243637, 22.024557560682297, 22.022080957889557, 22.01955407857895, 22.020358324050903, 22.017931908369064, 22.017100274562836, 22.01596999168396, 22.016072124242783, 22.014934986829758, 22.014654010534286, 22.012727290391922, 22.010071575641632, 22.00861757993698, 22.00962793827057, 22.005723118782043, 22.006474941968918, 22.006324887275696, 22.00632432103157, 22.003258049488068, 22.00368160009384, 22.002398043870926, 22.00192415714264, 21.999020278453827, 22.001094490289688, 21.99707192182541, 21.997043758630753, 21.99918681383133, 21.995119035243988, 21.997709035873413, 21.9953536093235, 21.993433266878128, 21.995204001665115, 21.992857813835144, 21.992251873016357, 21.99405926465988, 21.990942060947418, 21.98908296227455, 21.988870918750763, 21.98870161175728, 21.989793926477432, 21.987156927585602, 21.986181646585464, 21.988147795200348, 21.985516101121902, 21.986240476369858, 21.988235622644424, 21.984836101531982, 21.984290301799774, 21.983411073684692, 21.984173834323883, 21.983337491750717, 21.982856035232544, 21.982413411140442, 21.981150835752487, 21.981548726558685, 21.981521278619766, 21.979044556617737, 21.982405841350555, 21.97867000102997, 21.97786831855774, 21.9799807369709, 21.97712641954422, 21.97801560163498, 21.978073984384537, 21.976055711507797, 21.97691783308983, 21.975771963596344, 21.975454092025757, 21.975123912096024, 21.974384129047394, 21.974903613328934, 21.97380894422531, 21.97470858693123, 21.97483491897583, 21.97412544488907, 21.97468489408493, 21.975237399339676, 21.974452286958694, 21.97177603840828, 21.9752359688282, 21.975811153650284, 21.97389268875122, 21.974526822566986, 21.972579568624496, 21.9714894592762, 21.972506195306778, 21.971064567565918, 21.972029328346252, 21.96807500720024, 21.97200173139572, 21.969287514686584, 21.97076725959778, 21.968450158834457, 21.97073858976364, 21.969717353582382, 21.96991491317749, 21.968461841344833, 21.969549030065536, 21.967683374881744, 21.971230447292328, 21.96774610877037, 21.96714672446251, 21.967800199985504, 21.969288140535355, 21.967846602201462, 21.966873466968536, 21.96825087070465, 21.967750132083893, 21.968046605587006, 21.967428147792816, 21.96563282608986, 21.965459793806076, 21.966972172260284, 21.965562492609024, 21.967910677194595, 21.966510266065598, 21.965553879737854, 21.96664571762085, 21.966499000787735, 21.966771125793457, 21.96581283211708, 21.966068655252457, 21.962638467550278, 21.96542602777481, 21.963615983724594, 21.96430641412735, 21.96337503194809, 21.964551091194153, 21.965145230293274, 21.966288089752197, 21.963253021240234, 21.963940799236298, 21.963407278060913, 21.96330651640892, 21.964006453752518, 21.96348038315773, 21.96213909983635, 21.962476938962936, 21.96357324719429, 21.96385046839714, 21.964162975549698, 21.96237275004387, 21.96268981695175, 21.96464392542839, 21.9616257250309, 21.961573511362076, 21.962241291999817, 21.962131828069687, 21.962938904762268, 21.961930871009827, 21.959754556417465, 21.962123721837997, 21.960375249385834, 21.95984610915184, 21.96224319934845, 21.9617822766304, 21.95915573835373, 21.961147367954254, 21.96061199903488, 21.960487842559814, 21.96084064245224, 21.959914952516556, 21.960229337215424, 21.961833268404007, 21.962146788835526, 21.960381627082825, 21.95906239748001, 21.958544939756393, 21.95975211262703, 21.96221125125885, 21.96078732609749, 21.95904505252838, 21.959780752658844, 21.962662309408188, 21.958369433879852, 21.957881540060043, 21.959866493940353, 21.956913024187088, 21.961422234773636, 21.958844542503357, 21.95919582247734, 21.958301723003387, 21.959863513708115, 21.960164606571198, 21.959321171045303, 21.957952946424484, 21.957917004823685, 21.959931433200836, 21.95944106578827, 21.958974421024323, 21.958507478237152, 21.957591742277145, 21.957525730133057, 21.9574775993824, 21.957411229610443, 21.957738608121872, 21.960613578557968, 21.95677873492241, 21.960056722164154, 21.95833870768547, 21.957848697900772, 21.9565432369709, 21.95735701918602, 21.956458389759064, 21.95679810643196, 21.958017230033875, 21.95750167965889, 21.957886070013046, 21.956163614988327, 21.956253468990326, 21.957654058933258, 21.955128520727158, 21.95966863632202, 21.955476552248, 21.95832207798958, 21.955360382795334, 21.955294281244278, 21.956099271774292, 21.954804569482803, 21.956008166074753, 21.956787705421448, 21.956326216459274, 21.955481946468353, 21.956203907728195, 21.955739855766296, 21.955713540315628, 21.955205351114273, 21.95601949095726, 21.95682767033577, 21.95505878329277, 21.95589056611061, 21.957488536834717, 21.95579320192337, 21.956994622945786, 21.954035311937332, 21.956912726163864, 21.954365879297256, 21.956881046295166, 21.955955266952515, 21.956311136484146, 21.9579097032547, 21.957075208425522, 21.954964131116867, 21.955345660448074, 21.95568174123764, 21.955226004123688, 21.953934103250504, 21.955561131238937, 21.953880488872528, 21.95671048760414, 21.953792363405228, 21.957481414079666, 21.955374538898468, 21.95450869202614, 21.95489403605461, 21.955250173807144, 21.954821467399597, 21.956004559993744, 21.956395268440247, 21.955539733171463, 21.954672813415527, 21.955886006355286, 21.95416060090065, 21.95497888326645, 21.954103976488113, 21.95280161499977, 21.95320376753807, 21.95446479320526, 21.954345166683197, 21.955188244581223, 21.955621540546417, 21.954290986061096, 21.955064177513123, 21.9529832303524, 21.95208129286766, 21.955788522958755, 21.954536139965057, 21.953663021326065, 21.95404163002968, 21.954043298959732, 21.95602485537529, 21.9560749232769, 21.954308599233627, 21.954762786626816, 21.953814834356308, 21.952157855033875, 21.954640299081802, 21.95413863658905, 21.95248019695282, 21.95450484752655, 21.954907298088074, 21.953639835119247, 21.956105053424835, 21.95523038506508, 21.955258935689926, 21.954359084367752, 21.95309054851532, 21.95181295275688, 21.953822076320648, 21.9537855386734, 21.957100987434387, 21.95376345515251, 21.95625215768814, 21.95325717329979, 21.953656941652298, 21.952384889125824, 21.95111134648323, 21.95360565185547, 21.95521765947342, 21.95310452580452, 21.953906267881393, 21.955527305603027, 21.953440696001053, 21.953414916992188, 21.95546594262123, 21.952129632234573, 21.953736752271652, 21.954563587903976, 21.954137057065964, 21.95449846982956, 21.955324321985245, 21.95278012752533, 21.952360957860947, 21.951917946338654, 21.951477080583572, 21.952674984931946, 21.95305585861206, 21.953052699565887, 21.95300468802452, 21.952599197626114, 21.951729506254196, 21.953777760267258, 21.95423537492752, 21.954143673181534, 21.95208814740181, 21.951590925455093, 21.95199954509735, 21.951962798833847, 21.95401766896248, 21.951100289821625, 21.95150437951088, 21.952285170555115, 21.951866894960403, 21.95558074116707, 21.951826244592667, 21.954279959201813]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CUDA_LAUNCH_BLOCKING=1\n",
    "n_batch = 100\n",
    "nnModel = NeuralNetwork(data[0][0].shape[0], 2).float().to(device)\n",
    "opt = optim.Adam(nnModel.parameters(), lr=0.001)\n",
    "\n",
    "loader = torch_data.DataLoader(data, batch_size=100, shuffle=True)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "n_epochs = 500\n",
    "losses = []  # Potentially useful for debugging (loss should go down!)\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    epoch_loss = 0\n",
    "    for x, y in loader:\n",
    "        x = x.float().to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        preds = nnModel.forward(x.T).to(device)\n",
    "        loss = loss_fn(preds, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    losses.append(epoch_loss)\n",
    "\n",
    "print(losses)\n",
    "    \n",
    "PATH = './word2vec.pth'\n",
    "torch.save(nnModel.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "36a24639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 20:05:38,298 : INFO : collecting document frequencies\n",
      "2021-11-12 20:05:38,299 : INFO : PROGRESS: processing document #0\n",
      "2021-11-12 20:05:38,318 : INFO : TfidfModel lifecycle event {'msg': 'calculated IDF weights for 626 documents and 22599 features (33395 matrix non-zeros)', 'datetime': '2021-11-12T20:05:38.318771', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'initialize'}\n",
      "2021-11-12 20:05:38,320 : INFO : collecting all words and their counts\n",
      "2021-11-12 20:05:38,321 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-11-12 20:05:38,330 : INFO : collected 6437 word types from a corpus of 43135 raw words and 626 sentences\n",
      "2021-11-12 20:05:38,330 : INFO : Creating a fresh vocabulary\n",
      "2021-11-12 20:05:38,358 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 6437 unique words (100.0%% of original 6437, drops 0)', 'datetime': '2021-11-12T20:05:38.358305', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "2021-11-12 20:05:38,358 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 43135 word corpus (100.0%% of original 43135, drops 0)', 'datetime': '2021-11-12T20:05:38.358866', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "2021-11-12 20:05:38,409 : INFO : deleting the raw counts dictionary of 6437 items\n",
      "2021-11-12 20:05:38,410 : INFO : sample=0.001 downsamples 46 most-common words\n",
      "2021-11-12 20:05:38,411 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 34115.21059708384 word corpus (79.1%% of prior 43135)', 'datetime': '2021-11-12T20:05:38.411000', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, False, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, False, True, True, False, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, False, True, True, True, False, True, True, True, True, True, False, False, True, False, True, True, True, True, True, True, True, False, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, True, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 20:05:38,506 : INFO : estimated required memory for 6437 words and 81 dimensions: 7389676 bytes\n",
      "2021-11-12 20:05:38,506 : INFO : resetting layer weights\n",
      "2021-11-12 20:05:38,513 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-11-12T20:05:38.513871', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'build_vocab'}\n",
      "2021-11-12 20:05:38,514 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 6437 vocabulary and 81 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2021-11-12T20:05:38.514474', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'train'}\n",
      "2021-11-12 20:05:38,554 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 20:05:38,555 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 20:05:38,561 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 20:05:38,564 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 20:05:38,564 : INFO : EPOCH - 1 : training on 43135 raw words (34193 effective words) took 0.0s, 721455 effective words/s\n",
      "2021-11-12 20:05:38,597 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 20:05:38,598 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 20:05:38,600 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 20:05:38,601 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 20:05:38,602 : INFO : EPOCH - 2 : training on 43135 raw words (34073 effective words) took 0.0s, 964719 effective words/s\n",
      "2021-11-12 20:05:38,635 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 20:05:38,636 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 20:05:38,637 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 20:05:38,639 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 20:05:38,640 : INFO : EPOCH - 3 : training on 43135 raw words (34227 effective words) took 0.0s, 956930 effective words/s\n",
      "2021-11-12 20:05:38,673 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 20:05:38,675 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 20:05:38,676 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 20:05:38,677 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 20:05:38,678 : INFO : EPOCH - 4 : training on 43135 raw words (34163 effective words) took 0.0s, 946934 effective words/s\n",
      "2021-11-12 20:05:38,712 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 20:05:38,714 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 20:05:38,715 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 20:05:38,716 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 20:05:38,716 : INFO : EPOCH - 5 : training on 43135 raw words (34067 effective words) took 0.0s, 944527 effective words/s\n",
      "2021-11-12 20:05:38,717 : INFO : Word2Vec lifecycle event {'msg': 'training on 215675 raw words (170723 effective words) took 0.2s, 843369 effective words/s', 'datetime': '2021-11-12T20:05:38.717469', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'train'}\n",
      "2021-11-12 20:05:38,718 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=6437, vector_size=81, alpha=0.025)', 'datetime': '2021-11-12T20:05:38.718041', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'created'}\n",
      "2021-11-12 20:05:38,719 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'word2vec_test.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2021-11-12T20:05:38.719231', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'saving'}\n",
      "2021-11-12 20:05:38,719 : INFO : not storing attribute cum_table\n",
      "2021-11-12 20:05:38,782 : INFO : saved word2vec_test.model\n",
      "2021-11-12 20:05:38,787 : INFO : collecting all words and their counts\n",
      "2021-11-12 20:05:38,788 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2021-11-12 20:05:38,798 : INFO : collected 6437 word types and 626 unique tags from a corpus of 626 examples and 43135 words\n",
      "2021-11-12 20:05:38,799 : INFO : Creating a fresh vocabulary\n",
      "2021-11-12 20:05:38,831 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 6437 unique words (100.0%% of original 6437, drops 0)', 'datetime': '2021-11-12T20:05:38.831395', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "2021-11-12 20:05:38,832 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 43135 word corpus (100.0%% of original 43135, drops 0)', 'datetime': '2021-11-12T20:05:38.832143', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "2021-11-12 20:05:38,895 : INFO : deleting the raw counts dictionary of 6437 items\n",
      "2021-11-12 20:05:38,895 : INFO : sample=0.001 downsamples 46 most-common words\n",
      "2021-11-12 20:05:38,896 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 34115.21059708384 word corpus (79.1%% of prior 43135)', 'datetime': '2021-11-12T20:05:38.896310', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "2021-11-12 20:05:39,011 : INFO : estimated required memory for 6437 words and 81 dimensions: 7717700 bytes\n",
      "2021-11-12 20:05:39,012 : INFO : resetting layer weights\n",
      "2021-11-12 20:05:39,018 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 6437 vocabulary and 81 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2021-11-12T20:05:39.018264', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'train'}\n",
      "2021-11-12 20:05:39,101 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 20:05:39,104 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 20:05:39,106 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 20:05:39,114 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 20:05:39,115 : INFO : EPOCH - 1 : training on 43135 raw words (34566 effective words) took 0.1s, 367220 effective words/s\n",
      "2021-11-12 20:05:39,201 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 20:05:39,205 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 20:05:39,209 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 20:05:39,213 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 20:05:39,214 : INFO : EPOCH - 2 : training on 43135 raw words (34730 effective words) took 0.1s, 359081 effective words/s\n",
      "2021-11-12 20:05:39,297 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 20:05:39,298 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 20:05:39,300 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 20:05:39,309 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 20:05:39,310 : INFO : EPOCH - 3 : training on 43135 raw words (34778 effective words) took 0.1s, 372328 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 20:05:39,391 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 20:05:39,394 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 20:05:39,395 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 20:05:39,404 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 20:05:39,404 : INFO : EPOCH - 4 : training on 43135 raw words (34701 effective words) took 0.1s, 375943 effective words/s\n",
      "2021-11-12 20:05:39,487 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 20:05:39,491 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 20:05:39,492 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 20:05:39,501 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 20:05:39,501 : INFO : EPOCH - 5 : training on 43135 raw words (34789 effective words) took 0.1s, 371875 effective words/s\n",
      "2021-11-12 20:05:39,582 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 20:05:39,583 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 20:05:39,584 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 20:05:39,593 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 20:05:39,594 : INFO : EPOCH - 6 : training on 43135 raw words (34756 effective words) took 0.1s, 384627 effective words/s\n",
      "2021-11-12 20:05:39,677 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 20:05:39,679 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 20:05:39,681 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 20:05:39,690 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 20:05:39,690 : INFO : EPOCH - 7 : training on 43135 raw words (34763 effective words) took 0.1s, 369406 effective words/s\n",
      "2021-11-12 20:05:39,771 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 20:05:39,773 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 20:05:39,774 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 20:05:39,782 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 20:05:39,783 : INFO : EPOCH - 8 : training on 43135 raw words (34661 effective words) took 0.1s, 382857 effective words/s\n",
      "2021-11-12 20:05:39,863 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 20:05:39,867 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 20:05:39,868 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 20:05:39,875 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 20:05:39,875 : INFO : EPOCH - 9 : training on 43135 raw words (34625 effective words) took 0.1s, 384054 effective words/s\n",
      "2021-11-12 20:05:39,957 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-12 20:05:39,959 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-12 20:05:39,962 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-12 20:05:39,970 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-12 20:05:39,971 : INFO : EPOCH - 10 : training on 43135 raw words (34690 effective words) took 0.1s, 371748 effective words/s\n",
      "2021-11-12 20:05:39,971 : INFO : Doc2Vec lifecycle event {'msg': 'training on 431350 raw words (347059 effective words) took 1.0s, 364260 effective words/s', 'datetime': '2021-11-12T20:05:39.971895', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'train'}\n",
      "2021-11-12 20:05:39,972 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec(dm/m,d81,n5,w10,s0.001,t4)', 'datetime': '2021-11-12T20:05:39.972538', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'created'}\n",
      "2021-11-12 20:05:39,974 : INFO : Doc2Vec lifecycle event {'fname_or_handle': '/tmp/tmppfo5kkv1/doc2vec_tweets_notes_test', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2021-11-12T20:05:39.974753', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'saving'}\n",
      "2021-11-12 20:05:39,975 : INFO : not storing attribute cum_table\n",
      "2021-11-12 20:05:39,985 : INFO : saved /tmp/tmppfo5kkv1/doc2vec_tweets_notes_test\n",
      "2021-11-12 20:05:39,986 : INFO : loading Doc2Vec object from /tmp/tmppfo5kkv1/doc2vec_tweets_notes_test\n",
      "2021-11-12 20:05:39,991 : INFO : loading dv recursively from /tmp/tmppfo5kkv1/doc2vec_tweets_notes_test.dv.* with mmap=None\n",
      "2021-11-12 20:05:39,991 : INFO : loading wv recursively from /tmp/tmppfo5kkv1/doc2vec_tweets_notes_test.wv.* with mmap=None\n",
      "2021-11-12 20:05:39,992 : INFO : setting ignored attribute cum_table to None\n",
      "2021-11-12 20:05:40,084 : INFO : Doc2Vec lifecycle event {'fname': '/tmp/tmppfo5kkv1/doc2vec_tweets_notes_test', 'datetime': '2021-11-12T20:05:40.084113', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-50-generic-x86_64-with-glibc2.29', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "test_doc = [doc[0] for doc in test['tweet_note']]\n",
    "test_label = [(doc[1] > 0) for doc in test['tweet_note']]\n",
    "\n",
    "print(test_label)\n",
    "\n",
    "test_tokens = [simple_preprocess(doc) for doc in test_doc]\n",
    "test_BoW_corpus = [dictionary.doc2bow(doc, allow_update=True) for doc in test_tokens]\n",
    "tfidf = models.TfidfModel(test_BoW_corpus, smartirs='ntc')\n",
    "\n",
    "test_model = Word2Vec(sentences=test_tokens, vector_size=int(sent_len), window=10, min_count=1, workers=4)\n",
    "\n",
    "test_model.save(\"word2vec_test.model\")\n",
    "\n",
    "test_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(test_tokens)]\n",
    "test_model = Doc2Vec(test_documents, vector_size=int(sent_len), window=10, min_count=1, workers=4)\n",
    "\n",
    "\n",
    "fname = get_tmpfile(\"doc2vec_tweets_notes_test\")\n",
    "test_model.save(fname)\n",
    "\n",
    "test_model = Doc2Vec.load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "39b1a26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0561e-03, 9.9888e-01],\n",
      "        [5.4742e-06, 9.9999e-01],\n",
      "        [2.9068e-05, 9.9997e-01],\n",
      "        [4.2577e-06, 1.0000e+00],\n",
      "        [3.9784e-03, 9.9586e-01],\n",
      "        [1.3268e-06, 1.0000e+00],\n",
      "        [1.0793e-08, 1.0000e+00],\n",
      "        [2.6668e-04, 9.9971e-01],\n",
      "        [1.2678e-03, 9.9867e-01],\n",
      "        [1.1388e-07, 1.0000e+00],\n",
      "        [8.2403e-06, 9.9999e-01],\n",
      "        [2.4479e-04, 9.9972e-01],\n",
      "        [1.1644e-04, 9.9987e-01],\n",
      "        [3.3163e-08, 1.0000e+00],\n",
      "        [8.5275e-01, 1.4073e-01],\n",
      "        [1.2696e-05, 9.9998e-01],\n",
      "        [6.8761e-07, 1.0000e+00],\n",
      "        [2.0029e-08, 1.0000e+00],\n",
      "        [2.9269e-05, 9.9997e-01],\n",
      "        [3.1770e-05, 9.9997e-01],\n",
      "        [9.5481e-05, 9.9990e-01],\n",
      "        [2.4732e-07, 1.0000e+00],\n",
      "        [1.5096e-06, 1.0000e+00],\n",
      "        [1.9371e-03, 9.9792e-01],\n",
      "        [4.5934e-04, 9.9946e-01],\n",
      "        [8.2450e-01, 1.7131e-01],\n",
      "        [1.7885e-03, 9.9780e-01],\n",
      "        [5.1111e-05, 9.9994e-01],\n",
      "        [1.4477e-05, 9.9998e-01],\n",
      "        [2.2550e-03, 9.9772e-01],\n",
      "        [3.0474e-03, 9.9710e-01],\n",
      "        [3.4812e-04, 9.9960e-01],\n",
      "        [1.3759e-01, 8.6639e-01],\n",
      "        [4.3766e-02, 9.4646e-01],\n",
      "        [2.7276e-05, 9.9997e-01],\n",
      "        [1.5851e-05, 9.9998e-01],\n",
      "        [2.0218e-05, 9.9998e-01],\n",
      "        [5.7432e-04, 9.9937e-01],\n",
      "        [3.2516e-05, 9.9997e-01],\n",
      "        [2.1199e-08, 1.0000e+00],\n",
      "        [1.7028e-03, 9.9828e-01],\n",
      "        [1.4859e-05, 9.9998e-01],\n",
      "        [1.1882e-04, 9.9985e-01],\n",
      "        [8.6082e-05, 9.9991e-01],\n",
      "        [3.5859e-04, 9.9961e-01],\n",
      "        [1.2483e-05, 9.9998e-01],\n",
      "        [6.8112e-08, 1.0000e+00],\n",
      "        [2.6525e-04, 9.9968e-01],\n",
      "        [1.3069e-05, 9.9999e-01],\n",
      "        [2.3584e-06, 1.0000e+00],\n",
      "        [4.0632e-07, 1.0000e+00],\n",
      "        [2.5317e-06, 1.0000e+00],\n",
      "        [8.2193e-07, 1.0000e+00],\n",
      "        [8.5327e-07, 1.0000e+00],\n",
      "        [1.8678e-04, 9.9977e-01],\n",
      "        [2.3976e-03, 9.9689e-01],\n",
      "        [4.4283e-06, 1.0000e+00],\n",
      "        [2.9459e-05, 9.9997e-01],\n",
      "        [3.2482e-05, 9.9997e-01],\n",
      "        [8.2848e-05, 9.9991e-01],\n",
      "        [1.3792e-06, 1.0000e+00],\n",
      "        [6.4287e-01, 3.5744e-01],\n",
      "        [3.2201e-04, 9.9965e-01],\n",
      "        [9.8525e-07, 1.0000e+00],\n",
      "        [9.0905e-07, 1.0000e+00],\n",
      "        [6.2281e-04, 9.9926e-01],\n",
      "        [1.5064e-04, 9.9983e-01],\n",
      "        [3.7671e-04, 9.9957e-01],\n",
      "        [1.0504e-04, 9.9988e-01],\n",
      "        [2.1137e-04, 9.9975e-01],\n",
      "        [2.9290e-06, 1.0000e+00],\n",
      "        [1.6961e-03, 9.9768e-01],\n",
      "        [2.2462e-07, 1.0000e+00],\n",
      "        [7.3903e-02, 9.2576e-01],\n",
      "        [1.4615e-01, 8.4736e-01],\n",
      "        [8.4202e-05, 9.9991e-01],\n",
      "        [2.0168e-08, 1.0000e+00],\n",
      "        [1.4347e-01, 8.0892e-01],\n",
      "        [2.1567e-05, 9.9998e-01],\n",
      "        [7.5314e-05, 9.9991e-01],\n",
      "        [1.7280e-07, 1.0000e+00],\n",
      "        [4.8300e-04, 9.9954e-01],\n",
      "        [3.3478e-05, 9.9997e-01],\n",
      "        [2.0176e-06, 1.0000e+00],\n",
      "        [7.5630e-06, 9.9999e-01],\n",
      "        [2.9025e-07, 1.0000e+00],\n",
      "        [2.0573e-07, 1.0000e+00],\n",
      "        [7.9354e-04, 9.9922e-01],\n",
      "        [6.7121e-07, 1.0000e+00],\n",
      "        [3.7423e-03, 9.9643e-01],\n",
      "        [3.1594e-04, 9.9967e-01],\n",
      "        [5.8467e-05, 9.9994e-01],\n",
      "        [1.5442e-04, 9.9983e-01],\n",
      "        [9.6297e-08, 1.0000e+00],\n",
      "        [1.8808e-04, 9.9979e-01],\n",
      "        [4.3720e-06, 1.0000e+00],\n",
      "        [6.1829e-04, 9.9928e-01],\n",
      "        [7.6786e-09, 1.0000e+00],\n",
      "        [6.7525e-03, 9.9267e-01],\n",
      "        [6.7291e-05, 9.9993e-01]], device='cuda:2') tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1], device='cuda:2') torch.Size([100])\n",
      "tensor([[6.9796e-05, 9.9992e-01],\n",
      "        [2.4438e-04, 9.9972e-01],\n",
      "        [3.1569e-04, 9.9970e-01],\n",
      "        [4.5891e-06, 1.0000e+00],\n",
      "        [4.4569e-01, 5.3943e-01],\n",
      "        [3.5940e-05, 9.9996e-01],\n",
      "        [9.1536e-06, 9.9999e-01],\n",
      "        [9.1773e-05, 9.9989e-01],\n",
      "        [8.9080e-06, 9.9999e-01],\n",
      "        [1.1423e-06, 1.0000e+00],\n",
      "        [5.3618e-05, 9.9994e-01],\n",
      "        [2.4849e-02, 9.7529e-01],\n",
      "        [3.6720e-03, 9.9558e-01],\n",
      "        [5.1723e-06, 1.0000e+00],\n",
      "        [8.9623e-09, 1.0000e+00],\n",
      "        [1.4329e-07, 1.0000e+00],\n",
      "        [5.0775e-07, 1.0000e+00],\n",
      "        [3.1871e-07, 1.0000e+00],\n",
      "        [1.4732e-03, 9.9723e-01],\n",
      "        [4.2139e-03, 9.9479e-01],\n",
      "        [4.1374e-06, 1.0000e+00],\n",
      "        [4.7763e-08, 1.0000e+00],\n",
      "        [7.3857e-06, 9.9999e-01],\n",
      "        [4.6450e-05, 9.9995e-01],\n",
      "        [4.3580e-08, 1.0000e+00],\n",
      "        [1.0811e-02, 9.8776e-01],\n",
      "        [3.1185e-07, 1.0000e+00],\n",
      "        [1.6813e-05, 9.9998e-01],\n",
      "        [3.1639e-05, 9.9997e-01],\n",
      "        [3.6286e-07, 1.0000e+00],\n",
      "        [3.3234e-04, 9.9968e-01],\n",
      "        [1.9441e-03, 9.9820e-01],\n",
      "        [1.0446e-01, 8.8419e-01],\n",
      "        [2.0531e-06, 1.0000e+00],\n",
      "        [2.5367e-04, 9.9973e-01],\n",
      "        [4.5368e-10, 1.0000e+00],\n",
      "        [5.5479e-05, 9.9994e-01],\n",
      "        [7.1253e-03, 9.9079e-01],\n",
      "        [1.9691e-05, 9.9997e-01],\n",
      "        [1.7991e-07, 1.0000e+00],\n",
      "        [3.3108e-05, 9.9997e-01],\n",
      "        [6.2639e-07, 1.0000e+00],\n",
      "        [4.0335e-03, 9.9555e-01],\n",
      "        [2.4905e-02, 9.7230e-01],\n",
      "        [4.2136e-05, 9.9996e-01],\n",
      "        [7.7067e-05, 9.9992e-01],\n",
      "        [1.5092e-09, 1.0000e+00],\n",
      "        [5.2900e-07, 1.0000e+00],\n",
      "        [4.0194e-06, 1.0000e+00],\n",
      "        [9.1310e-06, 9.9999e-01],\n",
      "        [2.1839e-10, 1.0000e+00],\n",
      "        [1.9621e-06, 1.0000e+00],\n",
      "        [1.0415e-04, 9.9989e-01],\n",
      "        [1.6191e-05, 9.9998e-01],\n",
      "        [4.0353e-05, 9.9995e-01],\n",
      "        [5.0667e-08, 1.0000e+00],\n",
      "        [1.2461e-07, 1.0000e+00],\n",
      "        [1.3990e-04, 9.9986e-01],\n",
      "        [4.9216e-05, 9.9994e-01],\n",
      "        [7.3638e-07, 1.0000e+00],\n",
      "        [4.7159e-06, 9.9999e-01],\n",
      "        [4.3294e-03, 9.9541e-01],\n",
      "        [3.8353e-01, 5.8302e-01],\n",
      "        [3.6432e-08, 1.0000e+00],\n",
      "        [7.1258e-02, 9.1621e-01],\n",
      "        [2.1254e-04, 9.9975e-01],\n",
      "        [4.3270e-05, 9.9995e-01],\n",
      "        [2.1538e-03, 9.9800e-01],\n",
      "        [1.6756e-07, 1.0000e+00],\n",
      "        [1.7373e-06, 1.0000e+00],\n",
      "        [2.7047e-03, 9.9701e-01],\n",
      "        [1.5551e-04, 9.9982e-01],\n",
      "        [9.2821e-04, 9.9917e-01],\n",
      "        [1.0399e-04, 9.9988e-01],\n",
      "        [2.3907e-08, 1.0000e+00],\n",
      "        [1.6024e-06, 1.0000e+00],\n",
      "        [2.4342e-04, 9.9976e-01],\n",
      "        [2.0830e-08, 1.0000e+00],\n",
      "        [1.4883e-03, 9.9837e-01],\n",
      "        [3.2017e-06, 1.0000e+00],\n",
      "        [3.6481e-01, 6.1962e-01],\n",
      "        [3.7427e-07, 1.0000e+00],\n",
      "        [8.7575e-06, 9.9999e-01],\n",
      "        [2.1435e-03, 9.9801e-01],\n",
      "        [5.4602e-06, 9.9999e-01],\n",
      "        [6.1548e-03, 9.9328e-01],\n",
      "        [4.2260e-06, 1.0000e+00],\n",
      "        [1.3695e-07, 1.0000e+00],\n",
      "        [1.1750e-03, 9.9886e-01],\n",
      "        [4.4428e-09, 1.0000e+00],\n",
      "        [7.9179e-05, 9.9992e-01],\n",
      "        [7.4623e-04, 9.9902e-01],\n",
      "        [2.8951e-05, 9.9998e-01],\n",
      "        [7.8814e-03, 9.9066e-01],\n",
      "        [2.6912e-01, 7.2706e-01],\n",
      "        [4.9454e-07, 1.0000e+00],\n",
      "        [1.1154e-05, 9.9999e-01],\n",
      "        [1.1478e-06, 1.0000e+00],\n",
      "        [9.5501e-08, 1.0000e+00],\n",
      "        [3.3078e-04, 9.9962e-01]], device='cuda:2') tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], device='cuda:2') torch.Size([100])\n",
      "tensor([[1.9372e-02, 9.7773e-01],\n",
      "        [1.5646e-02, 9.8102e-01],\n",
      "        [1.4186e-09, 1.0000e+00],\n",
      "        [1.0205e-02, 9.8885e-01],\n",
      "        [1.4154e-03, 9.9842e-01],\n",
      "        [7.4494e-06, 9.9999e-01],\n",
      "        [5.8622e-05, 9.9992e-01],\n",
      "        [2.3219e-03, 9.9763e-01],\n",
      "        [5.6180e-04, 9.9936e-01],\n",
      "        [8.3602e-05, 9.9990e-01],\n",
      "        [3.4114e-04, 9.9959e-01],\n",
      "        [6.9212e-05, 9.9990e-01],\n",
      "        [1.9602e-03, 9.9786e-01],\n",
      "        [3.6237e-06, 1.0000e+00],\n",
      "        [1.7692e-03, 9.9825e-01],\n",
      "        [3.4494e-05, 9.9996e-01],\n",
      "        [3.6266e-04, 9.9958e-01],\n",
      "        [9.9905e-06, 9.9999e-01],\n",
      "        [2.8398e-06, 1.0000e+00],\n",
      "        [2.9608e-06, 1.0000e+00],\n",
      "        [1.4045e-03, 9.9841e-01],\n",
      "        [6.0252e-06, 9.9999e-01],\n",
      "        [1.0059e-03, 9.9884e-01],\n",
      "        [9.4521e-08, 1.0000e+00],\n",
      "        [7.6561e-04, 9.9912e-01],\n",
      "        [1.6467e-05, 9.9998e-01],\n",
      "        [3.2862e-03, 9.9569e-01],\n",
      "        [3.5416e-04, 9.9961e-01],\n",
      "        [1.5461e-05, 9.9998e-01],\n",
      "        [1.8272e-06, 1.0000e+00],\n",
      "        [2.8639e-04, 9.9970e-01],\n",
      "        [5.7231e-05, 9.9994e-01],\n",
      "        [1.2173e-06, 1.0000e+00],\n",
      "        [2.5478e-05, 9.9997e-01],\n",
      "        [3.5317e-04, 9.9961e-01],\n",
      "        [4.0564e-04, 9.9956e-01],\n",
      "        [1.6059e-04, 9.9982e-01],\n",
      "        [1.2389e-06, 1.0000e+00],\n",
      "        [1.4199e-05, 9.9999e-01],\n",
      "        [7.6091e-03, 9.9137e-01],\n",
      "        [1.8700e-05, 9.9998e-01],\n",
      "        [7.7463e-05, 9.9991e-01],\n",
      "        [2.4465e-05, 9.9997e-01],\n",
      "        [2.9084e-02, 9.6509e-01],\n",
      "        [3.0306e-06, 1.0000e+00],\n",
      "        [2.6690e-07, 1.0000e+00],\n",
      "        [6.5075e-05, 9.9991e-01],\n",
      "        [1.1370e-04, 9.9989e-01],\n",
      "        [4.0909e-05, 9.9995e-01],\n",
      "        [6.6478e-07, 1.0000e+00],\n",
      "        [3.6261e-06, 1.0000e+00],\n",
      "        [5.7159e-06, 9.9999e-01],\n",
      "        [1.6926e-05, 9.9998e-01],\n",
      "        [7.1730e-03, 9.9097e-01],\n",
      "        [6.3613e-05, 9.9993e-01],\n",
      "        [1.0094e-06, 1.0000e+00],\n",
      "        [1.5429e-05, 9.9998e-01],\n",
      "        [2.3745e-04, 9.9973e-01],\n",
      "        [1.7593e-01, 7.7641e-01],\n",
      "        [1.5977e-06, 1.0000e+00],\n",
      "        [6.3513e-04, 9.9936e-01],\n",
      "        [1.9163e-04, 9.9980e-01],\n",
      "        [2.1057e-09, 1.0000e+00],\n",
      "        [8.5610e-05, 9.9990e-01],\n",
      "        [4.1410e-04, 9.9955e-01],\n",
      "        [2.5899e-03, 9.9729e-01],\n",
      "        [4.4592e-06, 1.0000e+00],\n",
      "        [3.5331e-04, 9.9962e-01],\n",
      "        [1.9134e-07, 1.0000e+00],\n",
      "        [1.0435e-05, 9.9999e-01],\n",
      "        [2.7731e-04, 9.9968e-01],\n",
      "        [6.6969e-09, 1.0000e+00],\n",
      "        [5.8903e-05, 9.9995e-01],\n",
      "        [3.1390e-04, 9.9965e-01],\n",
      "        [3.0892e-09, 1.0000e+00],\n",
      "        [3.5524e-05, 9.9996e-01],\n",
      "        [5.4263e-04, 9.9931e-01],\n",
      "        [1.1135e-05, 9.9999e-01],\n",
      "        [1.0199e-08, 1.0000e+00],\n",
      "        [1.4673e-02, 9.7979e-01],\n",
      "        [7.5616e-06, 9.9999e-01],\n",
      "        [9.2136e-06, 9.9999e-01],\n",
      "        [6.7357e-08, 1.0000e+00],\n",
      "        [4.9789e-08, 1.0000e+00],\n",
      "        [7.4259e-03, 9.9030e-01],\n",
      "        [5.7768e-04, 9.9926e-01],\n",
      "        [5.2297e-05, 9.9994e-01],\n",
      "        [5.1444e-04, 9.9943e-01],\n",
      "        [4.0558e-05, 9.9995e-01],\n",
      "        [3.8957e-03, 9.9609e-01],\n",
      "        [1.0802e-03, 9.9888e-01],\n",
      "        [5.1682e-04, 9.9945e-01],\n",
      "        [1.1821e-02, 9.8831e-01],\n",
      "        [1.2381e-05, 9.9999e-01],\n",
      "        [2.4701e-04, 9.9976e-01],\n",
      "        [6.6104e-04, 9.9930e-01],\n",
      "        [6.4392e-06, 9.9999e-01],\n",
      "        [2.9387e-06, 1.0000e+00],\n",
      "        [4.3345e-05, 9.9995e-01],\n",
      "        [9.0507e-10, 1.0000e+00]], device='cuda:2') tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1], device='cuda:2') torch.Size([100])\n",
      "tensor([[4.2587e-04, 9.9951e-01],\n",
      "        [5.6026e-08, 1.0000e+00],\n",
      "        [2.6000e-06, 1.0000e+00],\n",
      "        [1.2822e-07, 1.0000e+00],\n",
      "        [6.0047e-04, 9.9923e-01],\n",
      "        [1.0117e-05, 9.9999e-01],\n",
      "        [3.6036e-02, 9.5832e-01],\n",
      "        [1.9093e-05, 9.9998e-01],\n",
      "        [1.6561e-08, 1.0000e+00],\n",
      "        [2.1751e-06, 1.0000e+00],\n",
      "        [8.4529e-12, 1.0000e+00],\n",
      "        [7.1761e-06, 9.9999e-01],\n",
      "        [3.1866e-05, 9.9997e-01],\n",
      "        [7.9429e-06, 9.9999e-01],\n",
      "        [1.2782e-08, 1.0000e+00],\n",
      "        [1.0033e-01, 8.6703e-01],\n",
      "        [1.9631e-07, 1.0000e+00],\n",
      "        [2.4184e-04, 9.9977e-01],\n",
      "        [1.1166e-06, 1.0000e+00],\n",
      "        [7.5937e-06, 9.9999e-01],\n",
      "        [2.9516e-03, 9.9637e-01],\n",
      "        [3.0449e-04, 9.9968e-01],\n",
      "        [1.8619e-08, 1.0000e+00],\n",
      "        [4.2405e-04, 9.9962e-01],\n",
      "        [2.5078e-08, 1.0000e+00],\n",
      "        [4.0309e-05, 9.9995e-01],\n",
      "        [7.4617e-07, 1.0000e+00],\n",
      "        [9.3867e-05, 9.9991e-01],\n",
      "        [3.9623e-04, 9.9955e-01],\n",
      "        [3.0748e-03, 9.9636e-01],\n",
      "        [2.3528e-06, 1.0000e+00],\n",
      "        [4.8466e-05, 9.9995e-01],\n",
      "        [9.0916e-07, 1.0000e+00],\n",
      "        [2.6775e-04, 9.9964e-01],\n",
      "        [1.4100e-04, 9.9984e-01],\n",
      "        [8.8006e-07, 1.0000e+00],\n",
      "        [2.5420e-03, 9.9699e-01],\n",
      "        [1.6255e-07, 1.0000e+00],\n",
      "        [1.9971e-07, 1.0000e+00],\n",
      "        [4.4140e-07, 1.0000e+00],\n",
      "        [1.2396e-05, 9.9999e-01],\n",
      "        [3.8964e-08, 1.0000e+00],\n",
      "        [1.2729e-04, 9.9987e-01],\n",
      "        [7.6290e-05, 9.9991e-01],\n",
      "        [1.3327e-04, 9.9985e-01],\n",
      "        [1.1089e-01, 8.8431e-01],\n",
      "        [7.7743e-05, 9.9991e-01],\n",
      "        [2.3999e-05, 9.9998e-01],\n",
      "        [2.0512e-04, 9.9976e-01],\n",
      "        [2.2163e-04, 9.9975e-01],\n",
      "        [5.8626e-06, 9.9999e-01],\n",
      "        [1.0009e-04, 9.9987e-01],\n",
      "        [1.0676e-02, 9.8674e-01],\n",
      "        [2.4909e-06, 1.0000e+00],\n",
      "        [2.1319e-05, 9.9998e-01],\n",
      "        [1.5416e-07, 1.0000e+00],\n",
      "        [2.3860e-08, 1.0000e+00],\n",
      "        [5.3674e-04, 9.9942e-01],\n",
      "        [4.3550e-06, 9.9999e-01],\n",
      "        [3.8277e-07, 1.0000e+00],\n",
      "        [3.2060e-04, 9.9967e-01],\n",
      "        [3.5380e-08, 1.0000e+00],\n",
      "        [1.5388e-06, 1.0000e+00],\n",
      "        [1.2501e-05, 9.9999e-01],\n",
      "        [2.9100e-03, 9.9671e-01],\n",
      "        [1.1914e-09, 1.0000e+00],\n",
      "        [2.0544e-03, 9.9736e-01],\n",
      "        [5.0589e-05, 9.9994e-01],\n",
      "        [1.2166e-11, 1.0000e+00],\n",
      "        [7.4943e-08, 1.0000e+00],\n",
      "        [3.0128e-03, 9.9707e-01],\n",
      "        [2.7044e-03, 9.9655e-01],\n",
      "        [4.6617e-08, 1.0000e+00],\n",
      "        [1.7632e-03, 9.9825e-01],\n",
      "        [5.5241e-05, 9.9994e-01],\n",
      "        [4.2783e-05, 9.9993e-01],\n",
      "        [1.6695e-03, 9.9821e-01],\n",
      "        [1.1723e-05, 9.9999e-01],\n",
      "        [3.3574e-04, 9.9963e-01],\n",
      "        [1.8597e-08, 1.0000e+00],\n",
      "        [9.0077e-03, 9.9027e-01],\n",
      "        [1.7289e-04, 9.9982e-01],\n",
      "        [2.5201e-05, 9.9997e-01],\n",
      "        [8.7514e-09, 1.0000e+00],\n",
      "        [5.0508e-05, 9.9992e-01],\n",
      "        [1.8484e-05, 9.9998e-01],\n",
      "        [1.1265e-04, 9.9990e-01],\n",
      "        [2.1816e-02, 9.8018e-01],\n",
      "        [1.1731e-07, 1.0000e+00],\n",
      "        [6.4210e-05, 9.9992e-01],\n",
      "        [2.9624e-07, 1.0000e+00],\n",
      "        [9.7982e-07, 1.0000e+00],\n",
      "        [1.4115e-04, 9.9987e-01],\n",
      "        [2.2829e-05, 9.9997e-01],\n",
      "        [8.8213e-09, 1.0000e+00],\n",
      "        [4.7741e-08, 1.0000e+00],\n",
      "        [2.3519e-07, 1.0000e+00],\n",
      "        [1.1440e-06, 1.0000e+00],\n",
      "        [3.8652e-07, 1.0000e+00],\n",
      "        [1.1013e-05, 9.9999e-01]], device='cuda:2') tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1], device='cuda:2') torch.Size([100])\n",
      "tensor([[2.4020e-05, 9.9997e-01],\n",
      "        [1.2868e-05, 9.9998e-01],\n",
      "        [1.3829e-05, 9.9998e-01],\n",
      "        [6.0089e-06, 9.9999e-01],\n",
      "        [1.7402e-04, 9.9980e-01],\n",
      "        [1.9603e-05, 9.9998e-01],\n",
      "        [1.7611e-09, 1.0000e+00],\n",
      "        [2.5338e-04, 9.9975e-01],\n",
      "        [1.2316e-07, 1.0000e+00],\n",
      "        [1.6550e-04, 9.9986e-01],\n",
      "        [2.1371e-05, 9.9998e-01],\n",
      "        [4.4259e-09, 1.0000e+00],\n",
      "        [7.4416e-10, 1.0000e+00],\n",
      "        [9.8050e-05, 9.9989e-01],\n",
      "        [1.1006e-02, 9.8680e-01],\n",
      "        [1.3267e-03, 9.9878e-01],\n",
      "        [1.3643e-08, 1.0000e+00],\n",
      "        [1.6389e-06, 1.0000e+00],\n",
      "        [7.6005e-06, 9.9999e-01],\n",
      "        [2.9846e-04, 9.9966e-01],\n",
      "        [9.9696e-04, 9.9884e-01],\n",
      "        [1.8786e-06, 1.0000e+00],\n",
      "        [2.8433e-07, 1.0000e+00],\n",
      "        [9.0580e-05, 9.9990e-01],\n",
      "        [1.8916e-04, 9.9982e-01],\n",
      "        [2.9135e-04, 9.9963e-01],\n",
      "        [1.8414e-03, 9.9783e-01],\n",
      "        [4.0111e-04, 9.9955e-01],\n",
      "        [2.7972e-03, 9.9668e-01],\n",
      "        [1.7404e-02, 9.8069e-01],\n",
      "        [3.8073e-06, 1.0000e+00],\n",
      "        [5.5454e-07, 1.0000e+00],\n",
      "        [1.1651e-05, 9.9999e-01],\n",
      "        [1.7849e-05, 9.9998e-01],\n",
      "        [6.7963e-06, 9.9999e-01],\n",
      "        [1.3303e-03, 9.9850e-01],\n",
      "        [5.0489e-05, 9.9994e-01],\n",
      "        [1.4800e-07, 1.0000e+00],\n",
      "        [6.0650e-06, 9.9999e-01],\n",
      "        [2.6066e-05, 9.9997e-01],\n",
      "        [6.2414e-04, 9.9939e-01],\n",
      "        [9.3406e-03, 9.9095e-01],\n",
      "        [1.2204e-04, 9.9983e-01],\n",
      "        [3.9795e-11, 1.0000e+00],\n",
      "        [3.0797e-01, 6.9398e-01],\n",
      "        [1.3521e-02, 9.8646e-01],\n",
      "        [3.0767e-05, 9.9997e-01],\n",
      "        [4.5422e-07, 1.0000e+00],\n",
      "        [9.5206e-07, 1.0000e+00],\n",
      "        [1.8268e-07, 1.0000e+00],\n",
      "        [3.8003e-06, 1.0000e+00],\n",
      "        [2.8268e-05, 9.9997e-01],\n",
      "        [4.6640e-02, 9.4357e-01],\n",
      "        [2.5159e-03, 9.9721e-01],\n",
      "        [3.8304e-05, 9.9996e-01],\n",
      "        [1.1413e-03, 9.9861e-01],\n",
      "        [1.0776e-07, 1.0000e+00],\n",
      "        [1.1091e-05, 9.9999e-01],\n",
      "        [4.2697e-07, 1.0000e+00],\n",
      "        [1.1393e-06, 1.0000e+00],\n",
      "        [4.7501e-05, 9.9994e-01],\n",
      "        [1.3662e-03, 9.9855e-01],\n",
      "        [2.8241e-05, 9.9997e-01],\n",
      "        [6.5881e-05, 9.9992e-01],\n",
      "        [2.0189e-09, 1.0000e+00],\n",
      "        [3.0222e-03, 9.9682e-01],\n",
      "        [2.6702e-04, 9.9974e-01],\n",
      "        [3.9177e-04, 9.9962e-01],\n",
      "        [4.5487e-07, 1.0000e+00],\n",
      "        [6.2698e-07, 1.0000e+00],\n",
      "        [1.4722e-05, 9.9998e-01],\n",
      "        [7.6797e-07, 1.0000e+00],\n",
      "        [5.4905e-07, 1.0000e+00],\n",
      "        [2.8412e-04, 9.9971e-01],\n",
      "        [9.4733e-05, 9.9990e-01],\n",
      "        [1.2696e-05, 9.9999e-01],\n",
      "        [2.1494e-10, 1.0000e+00],\n",
      "        [3.4770e-04, 9.9963e-01],\n",
      "        [3.2204e-04, 9.9967e-01],\n",
      "        [3.4479e-03, 9.9635e-01],\n",
      "        [1.4280e-01, 8.5536e-01],\n",
      "        [7.2276e-06, 9.9999e-01],\n",
      "        [1.7744e-07, 1.0000e+00],\n",
      "        [8.5735e-08, 1.0000e+00],\n",
      "        [4.0768e-04, 9.9957e-01],\n",
      "        [2.0587e-03, 9.9816e-01],\n",
      "        [8.5561e-05, 9.9990e-01],\n",
      "        [9.8715e-07, 1.0000e+00],\n",
      "        [2.2452e-07, 1.0000e+00],\n",
      "        [5.7171e-03, 9.9314e-01],\n",
      "        [2.0736e-02, 9.7954e-01],\n",
      "        [9.9182e-06, 9.9999e-01],\n",
      "        [2.7689e-04, 9.9967e-01],\n",
      "        [4.5930e-09, 1.0000e+00],\n",
      "        [2.9300e-05, 9.9997e-01],\n",
      "        [1.3764e-04, 9.9984e-01],\n",
      "        [4.5558e-07, 1.0000e+00],\n",
      "        [1.0540e-04, 9.9987e-01],\n",
      "        [1.6423e-05, 9.9998e-01],\n",
      "        [8.0060e-06, 9.9999e-01]], device='cuda:2') tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], device='cuda:2') torch.Size([100])\n",
      "tensor([[2.0290e-05, 9.9997e-01],\n",
      "        [1.1314e-05, 9.9999e-01],\n",
      "        [2.3707e-06, 1.0000e+00],\n",
      "        [7.3576e-03, 9.9158e-01],\n",
      "        [4.9987e-08, 1.0000e+00],\n",
      "        [1.4726e-06, 1.0000e+00],\n",
      "        [5.6708e-07, 1.0000e+00],\n",
      "        [3.0016e-04, 9.9965e-01],\n",
      "        [9.6870e-10, 1.0000e+00],\n",
      "        [1.0851e-08, 1.0000e+00],\n",
      "        [3.9529e-04, 9.9953e-01],\n",
      "        [1.9272e-10, 1.0000e+00],\n",
      "        [6.9703e-04, 9.9927e-01],\n",
      "        [1.5105e-05, 9.9998e-01],\n",
      "        [1.8768e-03, 9.9787e-01],\n",
      "        [6.1050e-09, 1.0000e+00],\n",
      "        [2.9290e-04, 9.9972e-01],\n",
      "        [4.2127e-07, 1.0000e+00],\n",
      "        [1.0090e-04, 9.9986e-01],\n",
      "        [6.2661e-07, 1.0000e+00],\n",
      "        [1.3352e-02, 9.8443e-01],\n",
      "        [9.0251e-02, 8.9109e-01],\n",
      "        [1.7839e-05, 9.9998e-01],\n",
      "        [5.4092e-05, 9.9994e-01],\n",
      "        [2.9724e-04, 9.9966e-01],\n",
      "        [2.6341e-01, 7.2328e-01],\n",
      "        [3.2851e-07, 1.0000e+00],\n",
      "        [4.0942e-08, 1.0000e+00],\n",
      "        [6.3850e-04, 9.9926e-01],\n",
      "        [9.8020e-02, 8.9633e-01],\n",
      "        [3.3598e-06, 1.0000e+00],\n",
      "        [1.2943e-06, 1.0000e+00],\n",
      "        [3.4387e-07, 1.0000e+00],\n",
      "        [6.3983e-03, 9.9284e-01],\n",
      "        [5.2425e-06, 9.9999e-01],\n",
      "        [8.6180e-05, 9.9992e-01],\n",
      "        [3.4198e-04, 9.9963e-01],\n",
      "        [2.5899e-04, 9.9972e-01],\n",
      "        [3.6633e-05, 9.9996e-01],\n",
      "        [2.6176e-07, 1.0000e+00],\n",
      "        [5.9635e-09, 1.0000e+00],\n",
      "        [4.2919e-04, 9.9951e-01],\n",
      "        [2.3692e-04, 9.9972e-01],\n",
      "        [2.0350e-03, 9.9756e-01],\n",
      "        [1.6102e-05, 9.9998e-01],\n",
      "        [6.9006e-07, 1.0000e+00],\n",
      "        [2.7037e-08, 1.0000e+00],\n",
      "        [1.4677e-04, 9.9982e-01],\n",
      "        [1.0519e-04, 9.9989e-01],\n",
      "        [2.2842e-04, 9.9977e-01],\n",
      "        [1.5783e-05, 9.9998e-01],\n",
      "        [3.5323e-03, 9.9662e-01],\n",
      "        [8.9508e-05, 9.9990e-01],\n",
      "        [8.8274e-05, 9.9991e-01],\n",
      "        [1.3862e-05, 9.9999e-01],\n",
      "        [1.0857e-07, 1.0000e+00],\n",
      "        [7.9722e-04, 9.9919e-01],\n",
      "        [7.8237e-03, 9.9171e-01],\n",
      "        [3.2805e-08, 1.0000e+00],\n",
      "        [9.9421e-06, 9.9999e-01],\n",
      "        [2.7102e-05, 9.9997e-01],\n",
      "        [1.8562e-07, 1.0000e+00],\n",
      "        [3.4735e-08, 1.0000e+00],\n",
      "        [1.1697e-03, 9.9889e-01],\n",
      "        [1.4638e-06, 1.0000e+00],\n",
      "        [4.7692e-04, 9.9955e-01],\n",
      "        [3.8538e-05, 9.9996e-01],\n",
      "        [5.0658e-06, 9.9999e-01],\n",
      "        [1.0504e-06, 1.0000e+00],\n",
      "        [1.8111e-08, 1.0000e+00],\n",
      "        [4.2113e-07, 1.0000e+00],\n",
      "        [2.7504e-06, 1.0000e+00],\n",
      "        [3.2828e-04, 9.9953e-01],\n",
      "        [7.5722e-08, 1.0000e+00],\n",
      "        [7.3670e-07, 1.0000e+00],\n",
      "        [1.7350e-04, 9.9981e-01],\n",
      "        [2.9859e-07, 1.0000e+00],\n",
      "        [6.1736e-07, 1.0000e+00],\n",
      "        [8.2704e-08, 1.0000e+00],\n",
      "        [1.1402e-05, 9.9998e-01],\n",
      "        [3.7482e-04, 9.9958e-01],\n",
      "        [9.1083e-09, 1.0000e+00],\n",
      "        [7.3769e-07, 1.0000e+00],\n",
      "        [4.3254e-08, 1.0000e+00],\n",
      "        [6.2519e-02, 9.0462e-01],\n",
      "        [7.8588e-04, 9.9909e-01],\n",
      "        [4.9402e-04, 9.9947e-01],\n",
      "        [1.5475e-04, 9.9983e-01],\n",
      "        [1.2168e-05, 9.9999e-01],\n",
      "        [4.7930e-05, 9.9995e-01],\n",
      "        [9.7920e-06, 9.9999e-01],\n",
      "        [4.7834e-05, 9.9995e-01],\n",
      "        [2.0983e-08, 1.0000e+00],\n",
      "        [5.5787e-06, 9.9999e-01],\n",
      "        [1.3174e-05, 9.9999e-01],\n",
      "        [2.2895e-01, 7.3889e-01],\n",
      "        [3.7298e-04, 9.9963e-01],\n",
      "        [1.3103e-06, 1.0000e+00],\n",
      "        [1.1097e-07, 1.0000e+00],\n",
      "        [1.3736e-04, 9.9986e-01]], device='cuda:2') tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1], device='cuda:2') torch.Size([100])\n",
      "tensor([[8.4551e-05, 9.9992e-01],\n",
      "        [9.1897e-08, 1.0000e+00],\n",
      "        [3.0937e-08, 1.0000e+00],\n",
      "        [3.5863e-05, 9.9995e-01],\n",
      "        [8.2789e-04, 9.9902e-01],\n",
      "        [2.8197e-04, 9.9969e-01],\n",
      "        [8.1902e-07, 1.0000e+00],\n",
      "        [8.8612e-05, 9.9991e-01],\n",
      "        [3.5834e-05, 9.9996e-01],\n",
      "        [1.0428e-04, 9.9988e-01],\n",
      "        [2.2699e-03, 9.9728e-01],\n",
      "        [1.6861e-02, 9.8139e-01],\n",
      "        [1.0849e-06, 1.0000e+00],\n",
      "        [2.9498e-07, 1.0000e+00],\n",
      "        [3.5890e-06, 1.0000e+00],\n",
      "        [5.0805e-07, 1.0000e+00],\n",
      "        [2.3720e-04, 9.9968e-01],\n",
      "        [1.2192e-04, 9.9989e-01],\n",
      "        [2.0765e-03, 9.9780e-01],\n",
      "        [1.3053e-04, 9.9986e-01],\n",
      "        [3.8129e-03, 9.9539e-01],\n",
      "        [2.0894e-08, 1.0000e+00],\n",
      "        [1.0904e-03, 9.9868e-01],\n",
      "        [5.3839e-09, 1.0000e+00],\n",
      "        [1.7501e-04, 9.9985e-01],\n",
      "        [6.2738e-05, 9.9994e-01]], device='cuda:2') tensor([0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], device='cuda:2') torch.Size([26])\n",
      "0.9265175718849841 tensor(0.3908, device='cuda:2')\n"
     ]
    }
   ],
   "source": [
    "test_data = [(torch.from_numpy((model.infer_vector(test_tokens[i]))).float().unsqueeze(1), int(test_label[i])) for i in range(len(test_tokens))]\n",
    "# print([doc[1] for doc in test_data])\n",
    "\n",
    "test_dataloader = torch_data.DataLoader(test_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# # testNnModel = torch.load(PATH)\n",
    "# # testNnModel.eval()\n",
    "\n",
    "nnModel.eval()\n",
    "\n",
    "total_acc, total_count = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_x, test_y in test_dataloader:\n",
    "        test_x = test_x.to(device)\n",
    "        test_y = test_y.to(device)\n",
    "        pred_test = nnModel(test_x.T)\n",
    "#         pred_test = torch.broadcast_to(torch.tensor([[0.0,0.9]]), (test_y.shape[0], 2))\n",
    "        print(pred_test, test_y, test_y.shape)\n",
    "        loss = loss_fn(pred_test.to(device), test_y.to(device))\n",
    "        total_acc += (pred_test.argmax(1).to(device) == test_y.to(device)).sum().item()\n",
    "        total_count += test_y.size(0)\n",
    "print(total_acc/total_count, loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb5ef89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
